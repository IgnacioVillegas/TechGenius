{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1f1xZWrDMJEAAEgDLE3-ohXDhvd3XkcZl","timestamp":1711619636350},{"file_id":"1O-SzsmT2GzIQyjmx_4Ab5kPKu8oti-hD","timestamp":1711618319238},{"file_id":"1Xp_h6A_vBO5HtxspWg-_y7peTp0d-arq","timestamp":1711618026799},{"file_id":"1D92bM9YIebcR_gA6IokuGIPNeqE9EfGC","timestamp":1702469895863},{"file_id":"1jPeWgTRfPTt7UHcQ57hQt7vSXCbuoIjF","timestamp":1687472281424}],"authorship_tag":"ABX9TyNng7yh0bwDHqyOmiB5WRrU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":279,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mb_5bl7G_n30","outputId":"dc7a0210-e1c2-44d6-cdfb-bdae06cf834c","pycharm":{"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1711622436122,"user_tz":-60,"elapsed":13467,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow==2.9.1 in /usr/local/lib/python3.10/dist-packages (2.9.1)\n","Requirement already satisfied: tensorflow_datasets==4.6.0 in /usr/local/lib/python3.10/dist-packages (4.6.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.6.3)\n","Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.12)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.4.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.2.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.62.1)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.9.0)\n","Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.9.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.1.2)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (18.1.1)\n","Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.25.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (24.0)\n","Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (3.19.6)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (67.7.2)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.16.0)\n","Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.9.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (0.36.0)\n","Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.9.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (4.10.0)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.9.1) (1.14.1)\n","Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (0.3.8)\n","Requirement already satisfied: etils[epath] in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (1.7.0)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (2.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (2.31.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (1.13.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (0.10.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets==4.6.0) (4.66.2)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.9.1) (0.43.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets==4.6.0) (2024.2.2)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.27.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.4.6)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.6)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.8.1)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.0.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[epath]->tensorflow_datasets==4.6.0) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[epath]->tensorflow_datasets==4.6.0) (6.4.0)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[epath]->tensorflow_datasets==4.6.0) (3.18.1)\n","Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets==4.6.0) (1.63.0)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (5.3.3)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (4.9)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (1.4.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (2.1.5)\n","Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (0.5.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1) (3.2.2)\n","Tensorflow version 2.9.1\n"]}],"source":["!pip install tensorflow==2.9.1 tensorflow_datasets==4.6.0\n","\n","from __future__ import absolute_import, division, print_function, unicode_literals\n","\n","import sys\n","\n","import os\n","import re\n","import numpy as np\n","#from time import time\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","import tensorflow_datasets as tfds\n","import pandas as pd\n","from tokenizers import Tokenizer\n","from tokenizers.models import BPE\n","from tokenizers.trainers import BpeTrainer\n","from tokenizers.pre_tokenizers import Whitespace\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import math\n","\n","tf.keras.utils.set_random_seed(1234)\n","\n","print(f\"Tensorflow version {tf.__version__}\")"]},{"cell_type":"code","execution_count":280,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Rz2ZbpAREmRA","outputId":"737f4da4-9f37-400b-ba41-dfa45fc1fd95","pycharm":{"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1711622436122,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["REPLICAS: 1\n"]}],"source":["try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n","    print(\"Running on TPU {}\".format(tpu.cluster_spec().as_dict()[\"worker\"]))\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","\n","print(f\"REPLICAS: {strategy.num_replicas_in_sync}\")"]},{"cell_type":"code","source":["!pip install tokenizers\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4iMHiw8mztFa","executionInfo":{"status":"ok","timestamp":1711622443058,"user_tz":-60,"elapsed":6939,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"2b459eff-417d-49d5-b59f-221bc0efc6b9"},"execution_count":281,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tokenizers in /usr/local/lib/python3.10/dist-packages (0.15.2)\n","Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers) (0.20.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.3)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2023.6.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.10.0)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (24.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/MyDrive/'BERIL_PROJECT'/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1I7MxSLjy4iT","executionInfo":{"status":"ok","timestamp":1711622445660,"user_tz":-60,"elapsed":2609,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"3216f923-5a92-4eec-b8d7-efccb1cac8cf"},"execution_count":282,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/MyDrive/BERIL_PROJECT\n"]}]},{"cell_type":"code","source":["%ls\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vNGwzYsJz0t7","executionInfo":{"status":"ok","timestamp":1711622445660,"user_tz":-60,"elapsed":16,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"c6018b2f-632b-4507-8fae-59d66c93a1e1"},"execution_count":283,"outputs":[{"output_type":"stream","name":"stdout","text":["BIG_DATASET.csv  CODE.ipynb  GENERATING_DATASET.ipynb  SHORT_DATASET.csv\n"]}]},{"cell_type":"code","source":["df = pd.read_csv('SHORT_DATASET.csv')"],"metadata":{"id":"3ya5LZ200eiP","executionInfo":{"status":"ok","timestamp":1711622445661,"user_tz":-60,"elapsed":12,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":284,"outputs":[]},{"cell_type":"code","source":["len(df)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3SgHUKQiC4Z9","executionInfo":{"status":"ok","timestamp":1711622445661,"user_tz":-60,"elapsed":12,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"548498b9-c8d1-4773-bfa7-6f5e5e9c16b4"},"execution_count":285,"outputs":[{"output_type":"execute_result","data":{"text/plain":["19"]},"metadata":{},"execution_count":285}]},{"cell_type":"code","source":["primera_columna = df.iloc[:, 0]\n","segunda_columna = df.iloc[:, 1]"],"metadata":{"id":"aAnzR1F_0s_Y","executionInfo":{"status":"ok","timestamp":1711622445661,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":286,"outputs":[]},{"cell_type":"markdown","source":["https://www.youtube.com/watch?v=MlDP2BVWjS0\n","\n","https://towardsdatascience.com/byte-pair-encoding-subword-based-tokenization-algorithm-77828a70bee0"],"metadata":{"id":"_lswKpVEFGbF"}},{"cell_type":"code","source":["def preprocess_sentence(sentence):\n","    sentence = sentence.lower().strip()\n","    # creating a space between a word and the punctuation following it\n","    # eg: \"he is a boy.\" => \"he is a boy .\"\n","    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n","    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n","    # removing contractions  didn t\n","    sentence = re.sub(r\"i'm\", \"i am\", sentence)\n","    sentence = re.sub(r\"he's\", \"he is\", sentence)\n","    sentence = re.sub(r\"she's\", \"she is\", sentence)\n","    sentence = re.sub(r\"it's\", \"it is\", sentence)\n","    sentence = re.sub(r\"that's\", \"that is\", sentence)\n","    sentence = re.sub(r\"what's\", \"that is\", sentence)\n","    sentence = re.sub(r\"where's\", \"where is\", sentence)\n","    sentence = re.sub(r\"how's\", \"how is\", sentence)\n","    sentence = re.sub(r\"\\'ll\", \" will\", sentence)\n","    sentence = re.sub(r\"\\'ve\", \" have\", sentence)\n","    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n","    sentence = re.sub(r\"\\'d\", \" would\", sentence)\n","    sentence = re.sub(r\"\\'re\", \" are\", sentence)\n","    sentence = re.sub(r\"won't\", \"will not\", sentence)\n","    sentence = re.sub(r\"didn t\", \"did not\", sentence)\n","    sentence = re.sub(r\"can't\", \"cannot\", sentence)\n","    sentence = re.sub(r\"n't\", \" not\", sentence)\n","    sentence = re.sub(r\"n'\", \"ng\", sentence)\n","    sentence = re.sub(r\"'bout\", \"about\", sentence)\n","    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n","    sentence = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", sentence)\n","    sentence = sentence.strip()\n","    return sentence"],"metadata":{"id":"Dz61bTCm5Duu","executionInfo":{"status":"ok","timestamp":1711622445661,"user_tz":-60,"elapsed":9,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":287,"outputs":[]},{"cell_type":"code","source":["print(primera_columna)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nOnEVEcgtNz2","executionInfo":{"status":"ok","timestamp":1711622445661,"user_tz":-60,"elapsed":9,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"ba27eed2-35a0-45b3-8cf3-7b90e071c7be"},"execution_count":288,"outputs":[{"output_type":"stream","name":"stdout","text":["0     I am thinking of soon upgrading from my now al...\n","1     I am thinking of soon upgrading from my now al...\n","2     I am thinking of soon upgrading from my now al...\n","3     I am thinking of soon upgrading from my now al...\n","4     I am thinking of soon upgrading from my now al...\n","5     I have a Poco M3 Pro 5G and it used to work fi...\n","6     I have a Poco M3 Pro 5G and it used to work fi...\n","7     Redmi note 12 pro 5G can be charged at 67 Watt...\n","8     Redmi note 12 pro 5G can be charged at 67 Watt...\n","9     Redmi note 12 pro 5G can be charged at 67 Watt...\n","10                              Which one do you prefer\n","11    Im starting to think that xiaomi might have fo...\n","12    Im starting to think that xiaomi might have fo...\n","13    Im starting to think that xiaomi might have fo...\n","14    Im starting to think that xiaomi might have fo...\n","15    Im starting to think that xiaomi might have fo...\n","16    There seems to have a massive transparent scre...\n","17    Last week I checked on updates and found that ...\n","18    Last week I checked on updates and found that ...\n","Name: Input, dtype: object\n"]}]},{"cell_type":"code","source":["primera_columna = primera_columna.apply(preprocess_sentence)"],"metadata":{"id":"_Ox2jW91sxIc","executionInfo":{"status":"ok","timestamp":1711622445661,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":289,"outputs":[]},{"cell_type":"code","source":["print(segunda_columna)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bgPmC1uVtAbZ","executionInfo":{"status":"ok","timestamp":1711622445662,"user_tz":-60,"elapsed":7,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"690a736b-4bd1-44fb-e920-8095a91fc9ce"},"execution_count":290,"outputs":[{"output_type":"stream","name":"stdout","text":["0     Hey, I am from Germany, and have had both .. F...\n","1     If you only care about performance, get the X6...\n","2     Poco X6 Pro is a rebranded Redmi K70E*, it's c...\n","3     13T Pro here just received the update. Didn't ...\n","4                                                X6 Pro\n","5     Well, either it's a software issues of the PMI...\n","6     i would let the battery completly die out for ...\n","7     No, because Xiaomi phones use Mi-FC standard f...\n","8     the charger is designed by the manufacturer to...\n","9     How do people even come up weiHow do people co...\n","10    YouTube forces an equalizer onto the users, wh...\n","11    See Xiaomi Hyper OS update tracker table [here...\n","12    Some people using 13t have received hyerOS. Mo...\n","13        We got one 13T in family, we have the update.\n","14        Greece here 13t updated a week ago in hyperos\n","15                     i have mine on indonesian rom ☹️\n","16                            https://imgur.com/72gT1Ge\n","17    That happened once to me in an older update.\\n...\n","18    I don't know , I still haven't got the hyper o...\n","Name: Output, dtype: object\n"]}]},{"cell_type":"code","source":["segunda_columna = segunda_columna.apply(preprocess_sentence)"],"metadata":{"id":"Setnf9ZptG9b","executionInfo":{"status":"ok","timestamp":1711622446331,"user_tz":-60,"elapsed":674,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":291,"outputs":[]},{"cell_type":"code","source":["combined_df = pd.concat([primera_columna, segunda_columna], axis=0)\n","print(combined_df.shape)\n","ultimas_columnas = combined_df.tail()\n","print(ultimas_columnas)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yx0p6H5O1_rv","executionInfo":{"status":"ok","timestamp":1711622446332,"user_tz":-60,"elapsed":24,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"e18cfe1a-515f-4d1f-d190-5c3c7d48f0d8"},"execution_count":292,"outputs":[{"output_type":"stream","name":"stdout","text":["(38,)\n","14          greece here t updated a week ago in hyperos\n","15                        i have mine on indonesian rom\n","16                              https imgur . com gt ge\n","17    that happened once to me in an older update . ...\n","18    i do not know , i still have not got the hyper...\n","dtype: object\n"]}]},{"cell_type":"code","source":["tokenizerTotal = Tokenizer(BPE(unk_tolen = \"<unk>\"))\n","trainerTotal = BpeTrainer(vocab_size = 2000, special_tokens = [\"<s>\", \"<pad>\", \"</s>\", \"<unk>\"])\n","tokenizerTotal.pre_tokenizer = Whitespace()\n","tokenizerTotal.train_from_iterator(combined_df, trainerTotal)"],"metadata":{"id":"lAXf4VrN9wRJ","executionInfo":{"status":"ok","timestamp":1711622446332,"user_tz":-60,"elapsed":22,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":293,"outputs":[]},{"cell_type":"code","source":["vueltas = 0\n","vocab_size = tokenizerTotal.get_vocab_size()\n","print(vocab_size)\n","for fila in primera_columna:\n","  vueltas += 1\n","  tokenizada = tokenizerTotal.encode(fila)\n","  print(\"............................\")\n","  print(fila)\n","\n","  print(tokenizada.tokens)\n","  print(tokenizada.ids)\n","  print(\"............................\")\n","  if(vueltas == 20):\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g9kXgNd-_vXR","executionInfo":{"status":"ok","timestamp":1711622446332,"user_tz":-60,"elapsed":22,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"26272cbf-9f2d-4f86-f501-d41af40ed1ed"},"execution_count":294,"outputs":[{"output_type":"stream","name":"stdout","text":["1029\n","............................\n","i am thinking of soon upgrading from my now almost years old remi note pro g uk , global version . i am debating whether to go for the redmi note pro or poco x pro . i have always used my phones only for browsing and fb , but i also watch a lot of k content on yt , so a good display is a must . a semi decent camera would also be nice . i do not feel the camera on my note was particularly good . i also want to maintain the smoothness and quick response of the note . based on all of that , which of the above do you think will be the better choice ? i think they will be roughly the same price here in the uk once the redmi note releases . thanks . edit thanks all for the recommendations . i went with the poco x pro !\n","['i', 'am', 'thinking', 'of', 'soon', 'upgrading', 'from', 'my', 'now', 'almost', 'years', 'old', 'remi', 'note', 'pro', 'g', 'uk', ',', 'global', 'version', '.', 'i', 'am', 'debating', 'whether', 'to', 'go', 'for', 'the', 'redmi', 'note', 'pro', 'or', 'poco', 'x', 'pro', '.', 'i', 'have', 'always', 'used', 'my', 'phones', 'only', 'for', 'browsing', 'and', 'fb', ',', 'but', 'i', 'also', 'watch', 'a', 'lot', 'of', 'k', 'content', 'on', 'yt', ',', 'so', 'a', 'good', 'display', 'is', 'a', 'must', '.', 'a', 'semi', 'decent', 'camera', 'would', 'also', 'be', 'nice', '.', 'i', 'do', 'not', 'feel', 'the', 'camera', 'on', 'my', 'note', 'was', 'particularly', 'good', '.', 'i', 'also', 'want', 'to', 'maintain', 'the', 'smoothness', 'and', 'quick', 'response', 'of', 'the', 'note', '.', 'based', 'on', 'all', 'of', 'that', ',', 'which', 'of', 'the', 'above', 'do', 'you', 'think', 'will', 'be', 'the', 'better', 'choice', '?', 'i', 'think', 'they', 'will', 'be', 'roughly', 'the', 'same', 'price', 'here', 'in', 'the', 'uk', 'once', 'the', 'redmi', 'note', 'releases', '.', 'thanks', '.', 'edit', 'thanks', 'all', 'for', 'the', 'recommendations', '.', 'i', 'went', 'with', 'the', 'poco', 'x', 'pro', '!']\n","[16, 63, 384, 66, 370, 404, 223, 96, 226, 296, 409, 256, 194, 80, 67, 14, 201, 5, 277, 242, 6, 16, 63, 414, 377, 53, 105, 64, 37, 160, 80, 67, 45, 98, 31, 67, 6, 16, 79, 412, 273, 96, 168, 152, 64, 398, 52, 329, 5, 124, 16, 100, 310, 8, 338, 66, 18, 401, 38, 264, 5, 57, 8, 159, 275, 58, 8, 224, 6, 8, 374, 243, 185, 139, 100, 55, 340, 6, 16, 123, 60, 186, 37, 185, 38, 96, 80, 192, 417, 159, 6, 16, 100, 354, 53, 406, 37, 402, 52, 386, 410, 66, 37, 80, 6, 393, 38, 180, 66, 111, 5, 156, 66, 37, 382, 123, 88, 107, 197, 55, 37, 221, 380, 7, 16, 107, 359, 197, 55, 407, 37, 177, 274, 211, 36, 37, 201, 265, 37, 160, 80, 403, 6, 198, 6, 368, 198, 180, 64, 37, 418, 6, 16, 263, 136, 37, 98, 31, 67, 4]\n","............................\n","............................\n","i am thinking of soon upgrading from my now almost years old remi note pro g uk , global version . i am debating whether to go for the redmi note pro or poco x pro . i have always used my phones only for browsing and fb , but i also watch a lot of k content on yt , so a good display is a must . a semi decent camera would also be nice . i do not feel the camera on my note was particularly good . i also want to maintain the smoothness and quick response of the note . based on all of that , which of the above do you think will be the better choice ? i think they will be roughly the same price here in the uk once the redmi note releases . thanks . edit thanks all for the recommendations . i went with the poco x pro !\n","['i', 'am', 'thinking', 'of', 'soon', 'upgrading', 'from', 'my', 'now', 'almost', 'years', 'old', 'remi', 'note', 'pro', 'g', 'uk', ',', 'global', 'version', '.', 'i', 'am', 'debating', 'whether', 'to', 'go', 'for', 'the', 'redmi', 'note', 'pro', 'or', 'poco', 'x', 'pro', '.', 'i', 'have', 'always', 'used', 'my', 'phones', 'only', 'for', 'browsing', 'and', 'fb', ',', 'but', 'i', 'also', 'watch', 'a', 'lot', 'of', 'k', 'content', 'on', 'yt', ',', 'so', 'a', 'good', 'display', 'is', 'a', 'must', '.', 'a', 'semi', 'decent', 'camera', 'would', 'also', 'be', 'nice', '.', 'i', 'do', 'not', 'feel', 'the', 'camera', 'on', 'my', 'note', 'was', 'particularly', 'good', '.', 'i', 'also', 'want', 'to', 'maintain', 'the', 'smoothness', 'and', 'quick', 'response', 'of', 'the', 'note', '.', 'based', 'on', 'all', 'of', 'that', ',', 'which', 'of', 'the', 'above', 'do', 'you', 'think', 'will', 'be', 'the', 'better', 'choice', '?', 'i', 'think', 'they', 'will', 'be', 'roughly', 'the', 'same', 'price', 'here', 'in', 'the', 'uk', 'once', 'the', 'redmi', 'note', 'releases', '.', 'thanks', '.', 'edit', 'thanks', 'all', 'for', 'the', 'recommendations', '.', 'i', 'went', 'with', 'the', 'poco', 'x', 'pro', '!']\n","[16, 63, 384, 66, 370, 404, 223, 96, 226, 296, 409, 256, 194, 80, 67, 14, 201, 5, 277, 242, 6, 16, 63, 414, 377, 53, 105, 64, 37, 160, 80, 67, 45, 98, 31, 67, 6, 16, 79, 412, 273, 96, 168, 152, 64, 398, 52, 329, 5, 124, 16, 100, 310, 8, 338, 66, 18, 401, 38, 264, 5, 57, 8, 159, 275, 58, 8, 224, 6, 8, 374, 243, 185, 139, 100, 55, 340, 6, 16, 123, 60, 186, 37, 185, 38, 96, 80, 192, 417, 159, 6, 16, 100, 354, 53, 406, 37, 402, 52, 386, 410, 66, 37, 80, 6, 393, 38, 180, 66, 111, 5, 156, 66, 37, 382, 123, 88, 107, 197, 55, 37, 221, 380, 7, 16, 107, 359, 197, 55, 407, 37, 177, 274, 211, 36, 37, 201, 265, 37, 160, 80, 403, 6, 198, 6, 368, 198, 180, 64, 37, 418, 6, 16, 263, 136, 37, 98, 31, 67, 4]\n","............................\n","............................\n","i am thinking of soon upgrading from my now almost years old remi note pro g uk , global version . i am debating whether to go for the redmi note pro or poco x pro . i have always used my phones only for browsing and fb , but i also watch a lot of k content on yt , so a good display is a must . a semi decent camera would also be nice . i do not feel the camera on my note was particularly good . i also want to maintain the smoothness and quick response of the note . based on all of that , which of the above do you think will be the better choice ? i think they will be roughly the same price here in the uk once the redmi note releases . thanks . edit thanks all for the recommendations . i went with the poco x pro !\n","['i', 'am', 'thinking', 'of', 'soon', 'upgrading', 'from', 'my', 'now', 'almost', 'years', 'old', 'remi', 'note', 'pro', 'g', 'uk', ',', 'global', 'version', '.', 'i', 'am', 'debating', 'whether', 'to', 'go', 'for', 'the', 'redmi', 'note', 'pro', 'or', 'poco', 'x', 'pro', '.', 'i', 'have', 'always', 'used', 'my', 'phones', 'only', 'for', 'browsing', 'and', 'fb', ',', 'but', 'i', 'also', 'watch', 'a', 'lot', 'of', 'k', 'content', 'on', 'yt', ',', 'so', 'a', 'good', 'display', 'is', 'a', 'must', '.', 'a', 'semi', 'decent', 'camera', 'would', 'also', 'be', 'nice', '.', 'i', 'do', 'not', 'feel', 'the', 'camera', 'on', 'my', 'note', 'was', 'particularly', 'good', '.', 'i', 'also', 'want', 'to', 'maintain', 'the', 'smoothness', 'and', 'quick', 'response', 'of', 'the', 'note', '.', 'based', 'on', 'all', 'of', 'that', ',', 'which', 'of', 'the', 'above', 'do', 'you', 'think', 'will', 'be', 'the', 'better', 'choice', '?', 'i', 'think', 'they', 'will', 'be', 'roughly', 'the', 'same', 'price', 'here', 'in', 'the', 'uk', 'once', 'the', 'redmi', 'note', 'releases', '.', 'thanks', '.', 'edit', 'thanks', 'all', 'for', 'the', 'recommendations', '.', 'i', 'went', 'with', 'the', 'poco', 'x', 'pro', '!']\n","[16, 63, 384, 66, 370, 404, 223, 96, 226, 296, 409, 256, 194, 80, 67, 14, 201, 5, 277, 242, 6, 16, 63, 414, 377, 53, 105, 64, 37, 160, 80, 67, 45, 98, 31, 67, 6, 16, 79, 412, 273, 96, 168, 152, 64, 398, 52, 329, 5, 124, 16, 100, 310, 8, 338, 66, 18, 401, 38, 264, 5, 57, 8, 159, 275, 58, 8, 224, 6, 8, 374, 243, 185, 139, 100, 55, 340, 6, 16, 123, 60, 186, 37, 185, 38, 96, 80, 192, 417, 159, 6, 16, 100, 354, 53, 406, 37, 402, 52, 386, 410, 66, 37, 80, 6, 393, 38, 180, 66, 111, 5, 156, 66, 37, 382, 123, 88, 107, 197, 55, 37, 221, 380, 7, 16, 107, 359, 197, 55, 407, 37, 177, 274, 211, 36, 37, 201, 265, 37, 160, 80, 403, 6, 198, 6, 368, 198, 180, 64, 37, 418, 6, 16, 263, 136, 37, 98, 31, 67, 4]\n","............................\n","............................\n","i am thinking of soon upgrading from my now almost years old remi note pro g uk , global version . i am debating whether to go for the redmi note pro or poco x pro . i have always used my phones only for browsing and fb , but i also watch a lot of k content on yt , so a good display is a must . a semi decent camera would also be nice . i do not feel the camera on my note was particularly good . i also want to maintain the smoothness and quick response of the note . based on all of that , which of the above do you think will be the better choice ? i think they will be roughly the same price here in the uk once the redmi note releases . thanks . edit thanks all for the recommendations . i went with the poco x pro !\n","['i', 'am', 'thinking', 'of', 'soon', 'upgrading', 'from', 'my', 'now', 'almost', 'years', 'old', 'remi', 'note', 'pro', 'g', 'uk', ',', 'global', 'version', '.', 'i', 'am', 'debating', 'whether', 'to', 'go', 'for', 'the', 'redmi', 'note', 'pro', 'or', 'poco', 'x', 'pro', '.', 'i', 'have', 'always', 'used', 'my', 'phones', 'only', 'for', 'browsing', 'and', 'fb', ',', 'but', 'i', 'also', 'watch', 'a', 'lot', 'of', 'k', 'content', 'on', 'yt', ',', 'so', 'a', 'good', 'display', 'is', 'a', 'must', '.', 'a', 'semi', 'decent', 'camera', 'would', 'also', 'be', 'nice', '.', 'i', 'do', 'not', 'feel', 'the', 'camera', 'on', 'my', 'note', 'was', 'particularly', 'good', '.', 'i', 'also', 'want', 'to', 'maintain', 'the', 'smoothness', 'and', 'quick', 'response', 'of', 'the', 'note', '.', 'based', 'on', 'all', 'of', 'that', ',', 'which', 'of', 'the', 'above', 'do', 'you', 'think', 'will', 'be', 'the', 'better', 'choice', '?', 'i', 'think', 'they', 'will', 'be', 'roughly', 'the', 'same', 'price', 'here', 'in', 'the', 'uk', 'once', 'the', 'redmi', 'note', 'releases', '.', 'thanks', '.', 'edit', 'thanks', 'all', 'for', 'the', 'recommendations', '.', 'i', 'went', 'with', 'the', 'poco', 'x', 'pro', '!']\n","[16, 63, 384, 66, 370, 404, 223, 96, 226, 296, 409, 256, 194, 80, 67, 14, 201, 5, 277, 242, 6, 16, 63, 414, 377, 53, 105, 64, 37, 160, 80, 67, 45, 98, 31, 67, 6, 16, 79, 412, 273, 96, 168, 152, 64, 398, 52, 329, 5, 124, 16, 100, 310, 8, 338, 66, 18, 401, 38, 264, 5, 57, 8, 159, 275, 58, 8, 224, 6, 8, 374, 243, 185, 139, 100, 55, 340, 6, 16, 123, 60, 186, 37, 185, 38, 96, 80, 192, 417, 159, 6, 16, 100, 354, 53, 406, 37, 402, 52, 386, 410, 66, 37, 80, 6, 393, 38, 180, 66, 111, 5, 156, 66, 37, 382, 123, 88, 107, 197, 55, 37, 221, 380, 7, 16, 107, 359, 197, 55, 407, 37, 177, 274, 211, 36, 37, 201, 265, 37, 160, 80, 403, 6, 198, 6, 368, 198, 180, 64, 37, 418, 6, 16, 263, 136, 37, 98, 31, 67, 4]\n","............................\n","............................\n","i am thinking of soon upgrading from my now almost years old remi note pro g uk , global version . i am debating whether to go for the redmi note pro or poco x pro . i have always used my phones only for browsing and fb , but i also watch a lot of k content on yt , so a good display is a must . a semi decent camera would also be nice . i do not feel the camera on my note was particularly good . i also want to maintain the smoothness and quick response of the note . based on all of that , which of the above do you think will be the better choice ? i think they will be roughly the same price here in the uk once the redmi note releases . thanks . edit thanks all for the recommendations . i went with the poco x pro !\n","['i', 'am', 'thinking', 'of', 'soon', 'upgrading', 'from', 'my', 'now', 'almost', 'years', 'old', 'remi', 'note', 'pro', 'g', 'uk', ',', 'global', 'version', '.', 'i', 'am', 'debating', 'whether', 'to', 'go', 'for', 'the', 'redmi', 'note', 'pro', 'or', 'poco', 'x', 'pro', '.', 'i', 'have', 'always', 'used', 'my', 'phones', 'only', 'for', 'browsing', 'and', 'fb', ',', 'but', 'i', 'also', 'watch', 'a', 'lot', 'of', 'k', 'content', 'on', 'yt', ',', 'so', 'a', 'good', 'display', 'is', 'a', 'must', '.', 'a', 'semi', 'decent', 'camera', 'would', 'also', 'be', 'nice', '.', 'i', 'do', 'not', 'feel', 'the', 'camera', 'on', 'my', 'note', 'was', 'particularly', 'good', '.', 'i', 'also', 'want', 'to', 'maintain', 'the', 'smoothness', 'and', 'quick', 'response', 'of', 'the', 'note', '.', 'based', 'on', 'all', 'of', 'that', ',', 'which', 'of', 'the', 'above', 'do', 'you', 'think', 'will', 'be', 'the', 'better', 'choice', '?', 'i', 'think', 'they', 'will', 'be', 'roughly', 'the', 'same', 'price', 'here', 'in', 'the', 'uk', 'once', 'the', 'redmi', 'note', 'releases', '.', 'thanks', '.', 'edit', 'thanks', 'all', 'for', 'the', 'recommendations', '.', 'i', 'went', 'with', 'the', 'poco', 'x', 'pro', '!']\n","[16, 63, 384, 66, 370, 404, 223, 96, 226, 296, 409, 256, 194, 80, 67, 14, 201, 5, 277, 242, 6, 16, 63, 414, 377, 53, 105, 64, 37, 160, 80, 67, 45, 98, 31, 67, 6, 16, 79, 412, 273, 96, 168, 152, 64, 398, 52, 329, 5, 124, 16, 100, 310, 8, 338, 66, 18, 401, 38, 264, 5, 57, 8, 159, 275, 58, 8, 224, 6, 8, 374, 243, 185, 139, 100, 55, 340, 6, 16, 123, 60, 186, 37, 185, 38, 96, 80, 192, 417, 159, 6, 16, 100, 354, 53, 406, 37, 402, 52, 386, 410, 66, 37, 80, 6, 393, 38, 180, 66, 111, 5, 156, 66, 37, 382, 123, 88, 107, 197, 55, 37, 221, 380, 7, 16, 107, 359, 197, 55, 407, 37, 177, 274, 211, 36, 37, 201, 265, 37, 160, 80, 403, 6, 198, 6, 368, 198, 180, 64, 37, 418, 6, 16, 263, 136, 37, 98, 31, 67, 4]\n","............................\n","............................\n","i have a poco m pro g and it used to work fine until last week where it just started sucking my battery even idling , to the point where i would take the phone out of the charger , use for minutes on social media youtube and instagram for the most part , have left for no reason , let it rest , and after minutes without even using it , it would be dead . also charges incredibly slow for some reason , on my charger , and other phones charger , only difference is mine says its fast charging when in reality it is not . last night it charged about during hours . i have seen people saying its miui , but i have been on that version for a decent while now and it was normal . i have tried recalibrating the battery , did not work . checked the health status of the charger and the battery , also good . factory reseted it , same problem . also , when i went to reset it , i had about charge , then when it restarted during the reset said it had so i plugged it into the charger , and out of no where it came back alive and with the still in it . similar stuff has happened , where i get to below battery and at any moment it might go to and die while im using it , or , most of the time , while idling . is there any fix for this ? tried everything i saw so far and nothing helped .\n","['i', 'have', 'a', 'poco', 'm', 'pro', 'g', 'and', 'it', 'used', 'to', 'work', 'fine', 'until', 'last', 'week', 'where', 'it', 'just', 'started', 'sucking', 'my', 'battery', 'even', 'idling', ',', 'to', 'the', 'point', 'where', 'i', 'would', 'take', 'the', 'phone', 'out', 'of', 'the', 'charger', ',', 'use', 'for', 'minutes', 'on', 'social', 'media', 'youtube', 'and', 'instagram', 'for', 'the', 'most', 'part', ',', 'have', 'left', 'for', 'no', 'reason', ',', 'let', 'it', 'rest', ',', 'and', 'after', 'minutes', 'without', 'even', 'using', 'it', ',', 'it', 'would', 'be', 'dead', '.', 'also', 'charges', 'incredibly', 'slow', 'for', 'some', 'reason', ',', 'on', 'my', 'charger', ',', 'and', 'other', 'phones', 'charger', ',', 'only', 'difference', 'is', 'mine', 'says', 'its', 'fast', 'charging', 'when', 'in', 'reality', 'it', 'is', 'not', '.', 'last', 'night', 'it', 'charged', 'about', 'during', 'hours', '.', 'i', 'have', 'seen', 'people', 'saying', 'its', 'miui', ',', 'but', 'i', 'have', 'been', 'on', 'that', 'version', 'for', 'a', 'decent', 'while', 'now', 'and', 'it', 'was', 'normal', '.', 'i', 'have', 'tried', 'recalibrating', 'the', 'battery', ',', 'did', 'not', 'work', '.', 'checked', 'the', 'health', 'status', 'of', 'the', 'charger', 'and', 'the', 'battery', ',', 'also', 'good', '.', 'factory', 'reseted', 'it', ',', 'same', 'problem', '.', 'also', ',', 'when', 'i', 'went', 'to', 'reset', 'it', ',', 'i', 'had', 'about', 'charge', ',', 'then', 'when', 'it', 'restarted', 'during', 'the', 'reset', 'said', 'it', 'had', 'so', 'i', 'plugged', 'it', 'into', 'the', 'charger', ',', 'and', 'out', 'of', 'no', 'where', 'it', 'came', 'back', 'alive', 'and', 'with', 'the', 'still', 'in', 'it', '.', 'similar', 'stuff', 'has', 'happened', ',', 'where', 'i', 'get', 'to', 'below', 'battery', 'and', 'at', 'any', 'moment', 'it', 'might', 'go', 'to', 'and', 'die', 'while', 'im', 'using', 'it', ',', 'or', ',', 'most', 'of', 'the', 'time', ',', 'while', 'idling', '.', 'is', 'there', 'any', 'fix', 'for', 'this', '?', 'tried', 'everything', 'i', 'saw', 'so', 'far', 'and', 'nothing', 'helped', '.']\n","[16, 79, 8, 98, 20, 67, 14, 52, 41, 273, 53, 397, 652, 408, 285, 317, 236, 41, 148, 392, 647, 96, 183, 182, 451, 5, 53, 37, 626, 236, 16, 139, 668, 37, 158, 103, 66, 37, 104, 5, 164, 64, 456, 38, 444, 537, 415, 52, 682, 64, 37, 196, 257, 5, 79, 619, 64, 225, 364, 5, 268, 41, 597, 5, 52, 534, 456, 636, 182, 385, 41, 5, 41, 139, 55, 504, 6, 100, 235, 655, 485, 64, 219, 364, 5, 38, 96, 104, 5, 52, 239, 168, 104, 5, 152, 672, 58, 517, 661, 166, 333, 446, 204, 36, 598, 41, 58, 60, 6, 285, 581, 41, 376, 135, 458, 680, 6, 16, 79, 617, 320, 662, 166, 499, 5, 124, 16, 79, 611, 38, 111, 242, 64, 8, 243, 269, 226, 52, 41, 192, 539, 6, 16, 79, 309, 683, 37, 183, 5, 250, 60, 397, 6, 312, 37, 654, 607, 66, 37, 104, 52, 37, 183, 5, 100, 159, 6, 688, 643, 41, 5, 177, 545, 6, 100, 5, 204, 16, 263, 53, 245, 41, 5, 16, 231, 135, 375, 5, 437, 204, 41, 599, 458, 37, 245, 646, 41, 231, 57, 16, 670, 41, 490, 37, 104, 5, 52, 103, 66, 225, 236, 41, 556, 325, 649, 52, 136, 37, 443, 36, 41, 6, 625, 544, 441, 530, 5, 236, 16, 240, 53, 612, 183, 52, 44, 122, 621, 41, 234, 105, 53, 52, 524, 269, 137, 385, 41, 5, 45, 5, 196, 66, 37, 588, 5, 269, 451, 6, 58, 218, 122, 455, 64, 229, 7, 309, 650, 16, 645, 57, 468, 52, 459, 687, 6]\n","............................\n","............................\n","i have a poco m pro g and it used to work fine until last week where it just started sucking my battery even idling , to the point where i would take the phone out of the charger , use for minutes on social media youtube and instagram for the most part , have left for no reason , let it rest , and after minutes without even using it , it would be dead . also charges incredibly slow for some reason , on my charger , and other phones charger , only difference is mine says its fast charging when in reality it is not . last night it charged about during hours . i have seen people saying its miui , but i have been on that version for a decent while now and it was normal . i have tried recalibrating the battery , did not work . checked the health status of the charger and the battery , also good . factory reseted it , same problem . also , when i went to reset it , i had about charge , then when it restarted during the reset said it had so i plugged it into the charger , and out of no where it came back alive and with the still in it . similar stuff has happened , where i get to below battery and at any moment it might go to and die while im using it , or , most of the time , while idling . is there any fix for this ? tried everything i saw so far and nothing helped .\n","['i', 'have', 'a', 'poco', 'm', 'pro', 'g', 'and', 'it', 'used', 'to', 'work', 'fine', 'until', 'last', 'week', 'where', 'it', 'just', 'started', 'sucking', 'my', 'battery', 'even', 'idling', ',', 'to', 'the', 'point', 'where', 'i', 'would', 'take', 'the', 'phone', 'out', 'of', 'the', 'charger', ',', 'use', 'for', 'minutes', 'on', 'social', 'media', 'youtube', 'and', 'instagram', 'for', 'the', 'most', 'part', ',', 'have', 'left', 'for', 'no', 'reason', ',', 'let', 'it', 'rest', ',', 'and', 'after', 'minutes', 'without', 'even', 'using', 'it', ',', 'it', 'would', 'be', 'dead', '.', 'also', 'charges', 'incredibly', 'slow', 'for', 'some', 'reason', ',', 'on', 'my', 'charger', ',', 'and', 'other', 'phones', 'charger', ',', 'only', 'difference', 'is', 'mine', 'says', 'its', 'fast', 'charging', 'when', 'in', 'reality', 'it', 'is', 'not', '.', 'last', 'night', 'it', 'charged', 'about', 'during', 'hours', '.', 'i', 'have', 'seen', 'people', 'saying', 'its', 'miui', ',', 'but', 'i', 'have', 'been', 'on', 'that', 'version', 'for', 'a', 'decent', 'while', 'now', 'and', 'it', 'was', 'normal', '.', 'i', 'have', 'tried', 'recalibrating', 'the', 'battery', ',', 'did', 'not', 'work', '.', 'checked', 'the', 'health', 'status', 'of', 'the', 'charger', 'and', 'the', 'battery', ',', 'also', 'good', '.', 'factory', 'reseted', 'it', ',', 'same', 'problem', '.', 'also', ',', 'when', 'i', 'went', 'to', 'reset', 'it', ',', 'i', 'had', 'about', 'charge', ',', 'then', 'when', 'it', 'restarted', 'during', 'the', 'reset', 'said', 'it', 'had', 'so', 'i', 'plugged', 'it', 'into', 'the', 'charger', ',', 'and', 'out', 'of', 'no', 'where', 'it', 'came', 'back', 'alive', 'and', 'with', 'the', 'still', 'in', 'it', '.', 'similar', 'stuff', 'has', 'happened', ',', 'where', 'i', 'get', 'to', 'below', 'battery', 'and', 'at', 'any', 'moment', 'it', 'might', 'go', 'to', 'and', 'die', 'while', 'im', 'using', 'it', ',', 'or', ',', 'most', 'of', 'the', 'time', ',', 'while', 'idling', '.', 'is', 'there', 'any', 'fix', 'for', 'this', '?', 'tried', 'everything', 'i', 'saw', 'so', 'far', 'and', 'nothing', 'helped', '.']\n","[16, 79, 8, 98, 20, 67, 14, 52, 41, 273, 53, 397, 652, 408, 285, 317, 236, 41, 148, 392, 647, 96, 183, 182, 451, 5, 53, 37, 626, 236, 16, 139, 668, 37, 158, 103, 66, 37, 104, 5, 164, 64, 456, 38, 444, 537, 415, 52, 682, 64, 37, 196, 257, 5, 79, 619, 64, 225, 364, 5, 268, 41, 597, 5, 52, 534, 456, 636, 182, 385, 41, 5, 41, 139, 55, 504, 6, 100, 235, 655, 485, 64, 219, 364, 5, 38, 96, 104, 5, 52, 239, 168, 104, 5, 152, 672, 58, 517, 661, 166, 333, 446, 204, 36, 598, 41, 58, 60, 6, 285, 581, 41, 376, 135, 458, 680, 6, 16, 79, 617, 320, 662, 166, 499, 5, 124, 16, 79, 611, 38, 111, 242, 64, 8, 243, 269, 226, 52, 41, 192, 539, 6, 16, 79, 309, 683, 37, 183, 5, 250, 60, 397, 6, 312, 37, 654, 607, 66, 37, 104, 52, 37, 183, 5, 100, 159, 6, 688, 643, 41, 5, 177, 545, 6, 100, 5, 204, 16, 263, 53, 245, 41, 5, 16, 231, 135, 375, 5, 437, 204, 41, 599, 458, 37, 245, 646, 41, 231, 57, 16, 670, 41, 490, 37, 104, 5, 52, 103, 66, 225, 236, 41, 556, 325, 649, 52, 136, 37, 443, 36, 41, 6, 625, 544, 441, 530, 5, 236, 16, 240, 53, 612, 183, 52, 44, 122, 621, 41, 234, 105, 53, 52, 524, 269, 137, 385, 41, 5, 45, 5, 196, 66, 37, 588, 5, 269, 451, 6, 58, 218, 122, 455, 64, 229, 7, 309, 650, 16, 645, 57, 468, 52, 459, 687, 6]\n","............................\n","............................\n","redmi note pro g can be charged at watts , however only by the official xiaomi charger . every other charger is limited to w or so . i understand some low quality charges would potentially damage the device however an apple or a dell usb c laptop charger must be able to deliver w safety . . is there any way to disable or increase the limit for alternative charges ?\n","['redmi', 'note', 'pro', 'g', 'can', 'be', 'charged', 'at', 'watts', ',', 'however', 'only', 'by', 'the', 'official', 'xiaomi', 'charger', '.', 'every', 'other', 'charger', 'is', 'limited', 'to', 'w', 'or', 'so', '.', 'i', 'understand', 'some', 'low', 'quality', 'charges', 'would', 'potentially', 'damage', 'the', 'device', 'however', 'an', 'apple', 'or', 'a', 'dell', 'usb', 'c', 'laptop', 'charger', 'must', 'be', 'able', 'to', 'deliver', 'w', 'safety', '.', '.', 'is', 'there', 'any', 'way', 'to', 'disable', 'or', 'increase', 'the', 'limit', 'for', 'alternative', 'charges', '?']\n","[160, 80, 67, 14, 200, 55, 376, 44, 515, 5, 303, 152, 208, 37, 532, 132, 104, 6, 302, 239, 104, 58, 523, 53, 30, 45, 57, 6, 16, 541, 219, 214, 301, 235, 139, 549, 528, 37, 457, 303, 39, 527, 45, 8, 503, 450, 10, 536, 104, 224, 55, 272, 53, 520, 30, 548, 6, 6, 58, 218, 122, 193, 53, 511, 45, 526, 37, 313, 64, 543, 235, 7]\n","............................\n","............................\n","redmi note pro g can be charged at watts , however only by the official xiaomi charger . every other charger is limited to w or so . i understand some low quality charges would potentially damage the device however an apple or a dell usb c laptop charger must be able to deliver w safety . . is there any way to disable or increase the limit for alternative charges ?\n","['redmi', 'note', 'pro', 'g', 'can', 'be', 'charged', 'at', 'watts', ',', 'however', 'only', 'by', 'the', 'official', 'xiaomi', 'charger', '.', 'every', 'other', 'charger', 'is', 'limited', 'to', 'w', 'or', 'so', '.', 'i', 'understand', 'some', 'low', 'quality', 'charges', 'would', 'potentially', 'damage', 'the', 'device', 'however', 'an', 'apple', 'or', 'a', 'dell', 'usb', 'c', 'laptop', 'charger', 'must', 'be', 'able', 'to', 'deliver', 'w', 'safety', '.', '.', 'is', 'there', 'any', 'way', 'to', 'disable', 'or', 'increase', 'the', 'limit', 'for', 'alternative', 'charges', '?']\n","[160, 80, 67, 14, 200, 55, 376, 44, 515, 5, 303, 152, 208, 37, 532, 132, 104, 6, 302, 239, 104, 58, 523, 53, 30, 45, 57, 6, 16, 541, 219, 214, 301, 235, 139, 549, 528, 37, 457, 303, 39, 527, 45, 8, 503, 450, 10, 536, 104, 224, 55, 272, 53, 520, 30, 548, 6, 6, 58, 218, 122, 193, 53, 511, 45, 526, 37, 313, 64, 543, 235, 7]\n","............................\n","............................\n","redmi note pro g can be charged at watts , however only by the official xiaomi charger . every other charger is limited to w or so . i understand some low quality charges would potentially damage the device however an apple or a dell usb c laptop charger must be able to deliver w safety . . is there any way to disable or increase the limit for alternative charges ?\n","['redmi', 'note', 'pro', 'g', 'can', 'be', 'charged', 'at', 'watts', ',', 'however', 'only', 'by', 'the', 'official', 'xiaomi', 'charger', '.', 'every', 'other', 'charger', 'is', 'limited', 'to', 'w', 'or', 'so', '.', 'i', 'understand', 'some', 'low', 'quality', 'charges', 'would', 'potentially', 'damage', 'the', 'device', 'however', 'an', 'apple', 'or', 'a', 'dell', 'usb', 'c', 'laptop', 'charger', 'must', 'be', 'able', 'to', 'deliver', 'w', 'safety', '.', '.', 'is', 'there', 'any', 'way', 'to', 'disable', 'or', 'increase', 'the', 'limit', 'for', 'alternative', 'charges', '?']\n","[160, 80, 67, 14, 200, 55, 376, 44, 515, 5, 303, 152, 208, 37, 532, 132, 104, 6, 302, 239, 104, 58, 523, 53, 30, 45, 57, 6, 16, 541, 219, 214, 301, 235, 139, 549, 528, 37, 457, 303, 39, 527, 45, 8, 503, 450, 10, 536, 104, 224, 55, 272, 53, 520, 30, 548, 6, 6, 58, 218, 122, 193, 53, 511, 45, 526, 37, 313, 64, 543, 235, 7]\n","............................\n","............................\n","which one do you prefer\n","['which', 'one', 'do', 'you', 'prefer']\n","[156, 360, 123, 88, 938]\n","............................\n","............................\n","im starting to think that xiaomi might have forgotten about the t because a poco f even got hyperos and not t which should be considered a higher priority by xiaomi since its a more expensive and a more premium feeling phone . what are you guy s opinions about this . maybe we just have to wait\n","['im', 'starting', 'to', 'think', 'that', 'xiaomi', 'might', 'have', 'forgotten', 'about', 'the', 't', 'because', 'a', 'poco', 'f', 'even', 'got', 'hyperos', 'and', 'not', 't', 'which', 'should', 'be', 'considered', 'a', 'higher', 'priority', 'by', 'xiaomi', 'since', 'its', 'a', 'more', 'expensive', 'and', 'a', 'more', 'premium', 'feeling', 'phone', '.', 'what', 'are', 'you', 'guy', 's', 'opinions', 'about', 'this', '.', 'maybe', 'we', 'just', 'have', 'to', 'wait']\n","[137, 391, 53, 107, 111, 132, 234, 79, 413, 135, 37, 27, 246, 8, 98, 13, 182, 144, 205, 52, 60, 27, 156, 311, 55, 321, 8, 405, 416, 208, 132, 244, 166, 8, 157, 395, 52, 8, 157, 314, 389, 158, 6, 316, 207, 88, 399, 26, 388, 135, 229, 6, 400, 191, 148, 79, 53, 184]\n","............................\n","............................\n","im starting to think that xiaomi might have forgotten about the t because a poco f even got hyperos and not t which should be considered a higher priority by xiaomi since its a more expensive and a more premium feeling phone . what are you guy s opinions about this . maybe we just have to wait\n","['im', 'starting', 'to', 'think', 'that', 'xiaomi', 'might', 'have', 'forgotten', 'about', 'the', 't', 'because', 'a', 'poco', 'f', 'even', 'got', 'hyperos', 'and', 'not', 't', 'which', 'should', 'be', 'considered', 'a', 'higher', 'priority', 'by', 'xiaomi', 'since', 'its', 'a', 'more', 'expensive', 'and', 'a', 'more', 'premium', 'feeling', 'phone', '.', 'what', 'are', 'you', 'guy', 's', 'opinions', 'about', 'this', '.', 'maybe', 'we', 'just', 'have', 'to', 'wait']\n","[137, 391, 53, 107, 111, 132, 234, 79, 413, 135, 37, 27, 246, 8, 98, 13, 182, 144, 205, 52, 60, 27, 156, 311, 55, 321, 8, 405, 416, 208, 132, 244, 166, 8, 157, 395, 52, 8, 157, 314, 389, 158, 6, 316, 207, 88, 399, 26, 388, 135, 229, 6, 400, 191, 148, 79, 53, 184]\n","............................\n","............................\n","im starting to think that xiaomi might have forgotten about the t because a poco f even got hyperos and not t which should be considered a higher priority by xiaomi since its a more expensive and a more premium feeling phone . what are you guy s opinions about this . maybe we just have to wait\n","['im', 'starting', 'to', 'think', 'that', 'xiaomi', 'might', 'have', 'forgotten', 'about', 'the', 't', 'because', 'a', 'poco', 'f', 'even', 'got', 'hyperos', 'and', 'not', 't', 'which', 'should', 'be', 'considered', 'a', 'higher', 'priority', 'by', 'xiaomi', 'since', 'its', 'a', 'more', 'expensive', 'and', 'a', 'more', 'premium', 'feeling', 'phone', '.', 'what', 'are', 'you', 'guy', 's', 'opinions', 'about', 'this', '.', 'maybe', 'we', 'just', 'have', 'to', 'wait']\n","[137, 391, 53, 107, 111, 132, 234, 79, 413, 135, 37, 27, 246, 8, 98, 13, 182, 144, 205, 52, 60, 27, 156, 311, 55, 321, 8, 405, 416, 208, 132, 244, 166, 8, 157, 395, 52, 8, 157, 314, 389, 158, 6, 316, 207, 88, 399, 26, 388, 135, 229, 6, 400, 191, 148, 79, 53, 184]\n","............................\n","............................\n","im starting to think that xiaomi might have forgotten about the t because a poco f even got hyperos and not t which should be considered a higher priority by xiaomi since its a more expensive and a more premium feeling phone . what are you guy s opinions about this . maybe we just have to wait\n","['im', 'starting', 'to', 'think', 'that', 'xiaomi', 'might', 'have', 'forgotten', 'about', 'the', 't', 'because', 'a', 'poco', 'f', 'even', 'got', 'hyperos', 'and', 'not', 't', 'which', 'should', 'be', 'considered', 'a', 'higher', 'priority', 'by', 'xiaomi', 'since', 'its', 'a', 'more', 'expensive', 'and', 'a', 'more', 'premium', 'feeling', 'phone', '.', 'what', 'are', 'you', 'guy', 's', 'opinions', 'about', 'this', '.', 'maybe', 'we', 'just', 'have', 'to', 'wait']\n","[137, 391, 53, 107, 111, 132, 234, 79, 413, 135, 37, 27, 246, 8, 98, 13, 182, 144, 205, 52, 60, 27, 156, 311, 55, 321, 8, 405, 416, 208, 132, 244, 166, 8, 157, 395, 52, 8, 157, 314, 389, 158, 6, 316, 207, 88, 399, 26, 388, 135, 229, 6, 400, 191, 148, 79, 53, 184]\n","............................\n","............................\n","im starting to think that xiaomi might have forgotten about the t because a poco f even got hyperos and not t which should be considered a higher priority by xiaomi since its a more expensive and a more premium feeling phone . what are you guy s opinions about this . maybe we just have to wait\n","['im', 'starting', 'to', 'think', 'that', 'xiaomi', 'might', 'have', 'forgotten', 'about', 'the', 't', 'because', 'a', 'poco', 'f', 'even', 'got', 'hyperos', 'and', 'not', 't', 'which', 'should', 'be', 'considered', 'a', 'higher', 'priority', 'by', 'xiaomi', 'since', 'its', 'a', 'more', 'expensive', 'and', 'a', 'more', 'premium', 'feeling', 'phone', '.', 'what', 'are', 'you', 'guy', 's', 'opinions', 'about', 'this', '.', 'maybe', 'we', 'just', 'have', 'to', 'wait']\n","[137, 391, 53, 107, 111, 132, 234, 79, 413, 135, 37, 27, 246, 8, 98, 13, 182, 144, 205, 52, 60, 27, 156, 311, 55, 321, 8, 405, 416, 208, 132, 244, 166, 8, 157, 395, 52, 8, 157, 314, 389, 158, 6, 316, 207, 88, 399, 26, 388, 135, 229, 6, 400, 191, 148, 79, 53, 184]\n","............................\n","............................\n","there seems to have a massive transparent screen when im opening bubbles on landscape mode . is there any fix to this ? picture in comments\n","['there', 'seems', 'to', 'have', 'a', 'massive', 'transparent', 'screen', 'when', 'im', 'opening', 'bubbles', 'on', 'landscape', 'mode', '.', 'is', 'there', 'any', 'fix', 'to', 'this', '?', 'picture', 'in', 'comments']\n","[218, 1005, 53, 79, 8, 937, 1019, 941, 204, 137, 872, 1011, 38, 1027, 832, 6, 58, 218, 122, 455, 53, 229, 7, 976, 36, 907]\n","............................\n","............................\n","last week i checked on updates and found that i can update to hyperos but since i was on my mobile plan i decided to wait until i got home . when i did , i checked again and it disappeared . i tried resetting the phone , changing the region , changing the name and nothing anyone had the same issue ?\n","['last', 'week', 'i', 'checked', 'on', 'updates', 'and', 'found', 'that', 'i', 'can', 'update', 'to', 'hyperos', 'but', 'since', 'i', 'was', 'on', 'my', 'mobile', 'plan', 'i', 'decided', 'to', 'wait', 'until', 'i', 'got', 'home', '.', 'when', 'i', 'did', ',', 'i', 'checked', 'again', 'and', 'it', 'disappeared', '.', 'i', 'tried', 'resetting', 'the', 'phone', ',', 'changing', 'the', 'region', ',', 'changing', 'the', 'name', 'and', 'nothing', 'anyone', 'had', 'the', 'same', 'issue', '?']\n","[285, 317, 16, 312, 38, 452, 52, 561, 111, 16, 200, 220, 53, 205, 124, 244, 16, 192, 38, 96, 622, 637, 16, 512, 53, 184, 408, 16, 144, 678, 6, 204, 16, 250, 5, 16, 312, 454, 52, 41, 686, 6, 16, 309, 644, 37, 158, 5, 460, 37, 663, 5, 460, 37, 579, 52, 459, 633, 231, 37, 177, 669, 7]\n","............................\n","............................\n","last week i checked on updates and found that i can update to hyperos but since i was on my mobile plan i decided to wait until i got home . when i did , i checked again and it disappeared . i tried resetting the phone , changing the region , changing the name and nothing anyone had the same issue ?\n","['last', 'week', 'i', 'checked', 'on', 'updates', 'and', 'found', 'that', 'i', 'can', 'update', 'to', 'hyperos', 'but', 'since', 'i', 'was', 'on', 'my', 'mobile', 'plan', 'i', 'decided', 'to', 'wait', 'until', 'i', 'got', 'home', '.', 'when', 'i', 'did', ',', 'i', 'checked', 'again', 'and', 'it', 'disappeared', '.', 'i', 'tried', 'resetting', 'the', 'phone', ',', 'changing', 'the', 'region', ',', 'changing', 'the', 'name', 'and', 'nothing', 'anyone', 'had', 'the', 'same', 'issue', '?']\n","[285, 317, 16, 312, 38, 452, 52, 561, 111, 16, 200, 220, 53, 205, 124, 244, 16, 192, 38, 96, 622, 637, 16, 512, 53, 184, 408, 16, 144, 678, 6, 204, 16, 250, 5, 16, 312, 454, 52, 41, 686, 6, 16, 309, 644, 37, 158, 5, 460, 37, 663, 5, 460, 37, 579, 52, 459, 633, 231, 37, 177, 669, 7]\n","............................\n"]}]},{"cell_type":"code","source":["def tokenizar_y_padding_FINAL(tokenizer, df):\n","  maximo = 120\n","  salida = []\n","  for f in df:\n","      frase =  [tokenizer.get_vocab_size()] + tokenizer.encode(f).ids + [tokenizer.get_vocab_size() + 1]\n","      salida.append(frase)\n","  print(\"MAXIMO encoder \", maximo)\n","  print(len(salida))\n","  salida = pad_sequences(salida, padding=\"post\", maxlen=maximo)\n","  return salida"],"metadata":{"id":"s2VzqGillIAP","executionInfo":{"status":"ok","timestamp":1711622446332,"user_tz":-60,"elapsed":18,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":295,"outputs":[]},{"cell_type":"code","source":["questions = tokenizar_y_padding_FINAL(tokenizerTotal, primera_columna)\n","answers = tokenizar_y_padding_FINAL(tokenizerTotal, segunda_columna)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0JQ3W2OVq3kM","executionInfo":{"status":"ok","timestamp":1711622446332,"user_tz":-60,"elapsed":17,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"57c12642-a380-4b98-bafd-7d95f0b985a7"},"execution_count":296,"outputs":[{"output_type":"stream","name":"stdout","text":["MAXIMO encoder  120\n","19\n","MAXIMO encoder  120\n","19\n"]}]},{"cell_type":"code","source":["def scaled_dot_product(q,k,v, maskLookAhead=None):\n","  denominador = q.shape[-1]\n","  parentesis = tf.matmul(q, tf.transpose(k, perm=[0, 1, 3, 2])) / math.sqrt(denominador)\n","  #maskPadding = tf.cast(tf.equal(parentesis, 0), tf.float32)\n","  #print(\"maskPadding!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\", maskPadding)\n","\n","  if maskLookAhead is not None:\n","        #maskPadding = tf.maximum(maskPadding, maskLookAhead)\n","        print(\"maaaaask look ahead\", maskLookAhead)\n","        #print(\"maskPadding + look ahead\", maskPadding)\n","        print(\"PARENTESIS ANTES\", parentesis)\n","        print(\"MASK * NEG\", maskLookAhead * -1e15)\n","        parentesis += maskLookAhead * -1e15\n","        print(\"PARENTESIS DESPUES\",parentesis)\n","        print(\"---------------------------------------------------------\")\n","  attention = tf.nn.softmax(parentesis, axis=-1)\n","  print(\"ATEENTION\", attention)\n","  print(\"V\", v)\n","  values = tf.matmul(attention, v)\n","  print(\"values\", values)\n","  return values"],"metadata":{"id":"RVifv7JBJy0m","executionInfo":{"status":"ok","timestamp":1711622446332,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":297,"outputs":[]},{"cell_type":"code","source":["class MultiHeadAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","      super(MultiHeadAttention, self).__init__()\n","      self.d_model = d_model  #es la embedding dimension\n","      self.num_heads = num_heads\n","      self.head_dim = d_model // num_heads #cada cabeza tiene esta dimension\n","      self.qkv_layer = tf.keras.layers.Dense(3 * d_model) #hacemos la dimension de emmbedding por tres para hacer en el mismo tensor q, k y v\n","      self.linear_layer = tf.keras.layers.Dense(d_model)\n","\n","  def call(self, inputs):\n","        x, mask = (\n","            inputs[\"x\"],\n","            inputs[\"mask\"]\n","        )\n","        print(\"x\", x)\n","        print(\"mask\", mask)\n","        #batch_size, sequence_length, d_model = tf.shape(x) #entra como 4 (batch_size), 140 seq_lenght, 512 d_model\n","        #batch_size, sequence_length, d_model = tf.shape(x).numpy().tolist()\n","        batch_size, sequence_length, d_model = tf.compat.v1.Session().run(tf.compat.v1.shape(x)).tolist()\n","\n","\n","\n","        print(\"batch_size, sequence_length, d_model\", batch_size, sequence_length, d_model)\n","        print(\"tf.shape(x)\", tf.shape(x))\n","        qkv = self.qkv_layer(x) #lo pasamos de d_model a d_modelx3\n","        print(\"tf.shape(qkv) por 3\", tf.shape(qkv))\n","        qkv = tf.reshape(qkv, (batch_size, sequence_length, self.num_heads, 3 * self.head_dim)) #lo dividimos en las cabezas\n","        print(\"tf.shape(qkv) le cambiamos a 4 dim\", tf.shape(qkv))\n","        qkv = tf.transpose(qkv, perm=(0, 2, 1, 3))#le cambiamod el orden para que esten las cabezas primero\n","        print(\"tf.shape(qkv) cambiamos de orden la cabeza\", tf.shape(qkv))\n","        q, k, v = tf.split(qkv, num_or_size_splits=3, axis=-1)#lo dividimos en 3 por la ultima dimension\n","        print(\"qkv\", tf.shape(q),tf.shape(k),tf.shape(v))\n","        values = scaled_dot_product(q, k, v, mask) #lo pasamos por la funcion de atencion que nos devuelve un tensor de 4, 8, 140, 64\n","        print(\"values\", tf.shape(values))#TENGO QUE METER EN LA LINEA DE ANTES MASKPADDING\n","        values = tf.reshape(tf.transpose(values, perm=(0, 2, 1, 3)), (batch_size, sequence_length, self.num_heads * self.head_dim)) #lo volvemos a poner primero seqlen y luego la dimension de las cabezas y las juntamos\n","        print(\"values cambiad0\", tf.shape(values))\n","        out = self.linear_layer(values)\n","        print(\"out\", tf.shape(out))\n","        print(\"out\", out)\n","        return out\n","\n"],"metadata":{"id":"v2uKIu72UYFh","executionInfo":{"status":"ok","timestamp":1711622446333,"user_tz":-60,"elapsed":11,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":298,"outputs":[]},{"cell_type":"code","source":["dataset = tf.data.Dataset.from_tensor_slices(\n","    (\n","        {\"inputs\": questions[1:, :], \"dec_inputs\": answers[1:, :]},\n","        {\"outputs\": answers[1:, :]}\n","    )\n","    )"],"metadata":{"id":"DgclrAdcqxSY","executionInfo":{"status":"ok","timestamp":1711622446333,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":299,"outputs":[]},{"cell_type":"code","source":["print(dataset)\n","print(dataset.cardinality().numpy())\n","print(len(dataset))\n","for fila in dataset.take(1):\n","    print(fila)\n","dataset = dataset.cache()\n","#dataset = dataset.shuffle(len(dataset))\n","dataset = dataset.batch(2)\n","#dataset = dataset.prefetch(tf.data.AUTOTUNE)\n","print(dataset.cardinality().numpy())\n","for fila in dataset.take(1):\n","    print(fila)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kmNifka8rEwX","executionInfo":{"status":"ok","timestamp":1711622446333,"user_tz":-60,"elapsed":10,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"1f05ed4e-8df5-40b1-9301-c6536e43a434"},"execution_count":300,"outputs":[{"output_type":"stream","name":"stdout","text":["<TensorSliceDataset element_spec=({'inputs': TensorSpec(shape=(120,), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(120,), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(120,), dtype=tf.int32, name=None)})>\n","18\n","18\n","({'inputs': <tf.Tensor: shape=(120,), dtype=int32, numpy=\n","array([  96,  168,  152,   64,  398,   52,  329,    5,  124,   16,  100,\n","        310,    8,  338,   66,   18,  401,   38,  264,    5,   57,    8,\n","        159,  275,   58,    8,  224,    6,    8,  374,  243,  185,  139,\n","        100,   55,  340,    6,   16,  123,   60,  186,   37,  185,   38,\n","         96,   80,  192,  417,  159,    6,   16,  100,  354,   53,  406,\n","         37,  402,   52,  386,  410,   66,   37,   80,    6,  393,   38,\n","        180,   66,  111,    5,  156,   66,   37,  382,  123,   88,  107,\n","        197,   55,   37,  221,  380,    7,   16,  107,  359,  197,   55,\n","        407,   37,  177,  274,  211,   36,   37,  201,  265,   37,  160,\n","         80,  403,    6,  198,    6,  368,  198,  180,   64,   37,  418,\n","          6,   16,  263,  136,   37,   98,   31,   67,    4, 1030],\n","      dtype=int32)>, 'dec_inputs': <tf.Tensor: shape=(120,), dtype=int32, numpy=\n","array([1029,  146,   88,  152,  638,  135, 1012,    5,  240,   37,   31,\n","         67,    5,  146,   88,  638,  135,  185,    5,  628,  301,  240,\n","         37,   67,    5,   16,   79,   37,   67,   52,   16,   63,  492,\n","        926,  136,   41,    5,  910,  223,   67,   52,   37,  966,   58,\n","        965,    6, 1030,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n","      dtype=int32)>}, {'outputs': <tf.Tensor: shape=(120,), dtype=int32, numpy=\n","array([1029,  146,   88,  152,  638,  135, 1012,    5,  240,   37,   31,\n","         67,    5,  146,   88,  638,  135,  185,    5,  628,  301,  240,\n","         37,   67,    5,   16,   79,   37,   67,   52,   16,   63,  492,\n","        926,  136,   41,    5,  910,  223,   67,   52,   37,  966,   58,\n","        965,    6, 1030,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","          0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n","      dtype=int32)>})\n","9\n","({'inputs': <tf.Tensor: shape=(2, 120), dtype=int32, numpy=\n","array([[  96,  168,  152,   64,  398,   52,  329,    5,  124,   16,  100,\n","         310,    8,  338,   66,   18,  401,   38,  264,    5,   57,    8,\n","         159,  275,   58,    8,  224,    6,    8,  374,  243,  185,  139,\n","         100,   55,  340,    6,   16,  123,   60,  186,   37,  185,   38,\n","          96,   80,  192,  417,  159,    6,   16,  100,  354,   53,  406,\n","          37,  402,   52,  386,  410,   66,   37,   80,    6,  393,   38,\n","         180,   66,  111,    5,  156,   66,   37,  382,  123,   88,  107,\n","         197,   55,   37,  221,  380,    7,   16,  107,  359,  197,   55,\n","         407,   37,  177,  274,  211,   36,   37,  201,  265,   37,  160,\n","          80,  403,    6,  198,    6,  368,  198,  180,   64,   37,  418,\n","           6,   16,  263,  136,   37,   98,   31,   67,    4, 1030],\n","       [  96,  168,  152,   64,  398,   52,  329,    5,  124,   16,  100,\n","         310,    8,  338,   66,   18,  401,   38,  264,    5,   57,    8,\n","         159,  275,   58,    8,  224,    6,    8,  374,  243,  185,  139,\n","         100,   55,  340,    6,   16,  123,   60,  186,   37,  185,   38,\n","          96,   80,  192,  417,  159,    6,   16,  100,  354,   53,  406,\n","          37,  402,   52,  386,  410,   66,   37,   80,    6,  393,   38,\n","         180,   66,  111,    5,  156,   66,   37,  382,  123,   88,  107,\n","         197,   55,   37,  221,  380,    7,   16,  107,  359,  197,   55,\n","         407,   37,  177,  274,  211,   36,   37,  201,  265,   37,  160,\n","          80,  403,    6,  198,    6,  368,  198,  180,   64,   37,  418,\n","           6,   16,  263,  136,   37,   98,   31,   67,    4, 1030]],\n","      dtype=int32)>, 'dec_inputs': <tf.Tensor: shape=(2, 120), dtype=int32, numpy=\n","array([[1029,  146,   88,  152,  638,  135, 1012,    5,  240,   37,   31,\n","          67,    5,  146,   88,  638,  135,  185,    5,  628,  301,  240,\n","          37,   67,    5,   16,   79,   37,   67,   52,   16,   63,  492,\n","         926,  136,   41,    5,  910,  223,   67,   52,   37,  966,   58,\n","         965,    6, 1030,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n","       [1029,   98,   31,   67,   58,    8,  998,  160,   18,   12,    5,\n","          41,   58,  321,    8,  157,  314,  447,  521,   53,   37,   80,\n","          67, 1030,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n","      dtype=int32)>}, {'outputs': <tf.Tensor: shape=(2, 120), dtype=int32, numpy=\n","array([[1029,  146,   88,  152,  638,  135, 1012,    5,  240,   37,   31,\n","          67,    5,  146,   88,  638,  135,  185,    5,  628,  301,  240,\n","          37,   67,    5,   16,   79,   37,   67,   52,   16,   63,  492,\n","         926,  136,   41,    5,  910,  223,   67,   52,   37,  966,   58,\n","         965,    6, 1030,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n","       [1029,   98,   31,   67,   58,    8,  998,  160,   18,   12,    5,\n","          41,   58,  321,    8,  157,  314,  447,  521,   53,   37,   80,\n","          67, 1030,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","           0,    0,    0,    0,    0,    0,    0,    0,    0,    0]],\n","      dtype=int32)>})\n"]}]},{"cell_type":"code","source":["dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qmv1cv1-8-ze","executionInfo":{"status":"ok","timestamp":1711622446333,"user_tz":-60,"elapsed":8,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"caab0fcf-269a-40e4-8197-c0f43125f8c9"},"execution_count":301,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<BatchDataset element_spec=({'inputs': TensorSpec(shape=(None, 120), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(None, 120), dtype=tf.int32, name=None)}, {'outputs': TensorSpec(shape=(None, 120), dtype=tf.int32, name=None)})>"]},"metadata":{},"execution_count":301}]},{"cell_type":"markdown","source":["MASKS"],"metadata":{"id":"q2KDnNQjBG9v"}},{"cell_type":"code","source":["### es equivalente a create_look_ahead_mask\n","\n","def create_look_ahead_mask(x):\n","    seq_len = tf.shape(x)[1]\n","    look_ahead_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n","    return look_ahead_mask\n","\n","def crear_masks(x, lookAheadMask = None):\n","    mask = tf.cast(tf.math.equal(x, 0), tf.float32)\n","    maskA= mask[:, tf.newaxis, tf.newaxis, :]\n","    maskB = mask[:, tf.newaxis, :,tf.newaxis]\n","    if lookAheadMask is None:\n","      seq_len = tf.shape(x)[1]\n","      lookAheadMask = tf.zeros((seq_len, seq_len))\n","    maskFinal = tf.maximum(maskA,lookAheadMask)\n","    maskFinal2 = tf.maximum(maskB,maskFinal)\n","    return maskFinal2\n","\n"],"metadata":{"id":"T8MzjgXu-V1x","executionInfo":{"status":"ok","timestamp":1711622446333,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":302,"outputs":[]},{"cell_type":"code","source":["\n","def create_mask_cross(encoder_inputs, decoder_inputs):\n","    encMask = tf.cast(tf.math.equal(encoder_inputs, 0), tf.float32)\n","    decMask = tf.cast(tf.math.equal(decoder_inputs, 0), tf.float32)\n","    #print(\"encMask\", encMask)\n","    #print(\"decMask\", decMask)\n","    encMaskAmp= encMask[:, tf.newaxis, tf.newaxis, :]\n","    decMaskAmp = decMask[:, tf.newaxis, :,tf.newaxis]\n","    #print(\"encMaskAmp\", encMaskAmp)\n","    #print(\"decMaskAmp\", decMaskAmp)\n","    seq_len = tf.shape(encoder_inputs)[1]\n","    maskBase = tf.zeros((seq_len, seq_len))\n","    #print(\"mask base\", maskBase)\n","    #print(\"pruebo maximum con encMaskAmp\", tf.maximum(encMaskAmp,maskBase))\n","    #print(\"pruebo maximum con decMaskAmp\", tf.maximum(decMaskAmp,maskBase))\n","    maskFinal = tf.maximum(encMaskAmp,maskBase)\n","    maskFinal2 = tf.maximum(decMaskAmp,maskFinal)\n","    return maskFinal2\n","\n","\n"],"metadata":{"id":"v9aSzP_E4vKf","executionInfo":{"status":"ok","timestamp":1711622446333,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":303,"outputs":[]},{"cell_type":"markdown","source":["EMPEZAMOS CON EL TRANSFORMER"],"metadata":{"id":"S2AvfcqWLl56"}},{"cell_type":"markdown","source":["POSITIONAL ENCODER"],"metadata":{"id":"fkf3vPZPMfEk"}},{"cell_type":"code","source":["class PositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self, d_model, max_sequence_length):\n","        super(PositionalEncoding, self).__init__()\n","        self.max_sequence_length = max_sequence_length\n","        self.d_model = d_model\n","\n","    def call(self, inputs):\n","    #def call(self):\n","        i2 = tf.range(0, self.d_model, 2, dtype=tf.float32)\n","        print(\"i2\", i2)\n","        print(\"i2 shape\", tf.shape(i2))\n","        denominador = tf.pow(10000.0, i2 / self.d_model)\n","        print(\"denominador\", denominador)\n","        print(\"denominador shape\", tf.shape(denominador))\n","        pos = tf.range(self.max_sequence_length, dtype=tf.float32)\n","        print(\"pos\", pos)\n","        print(\"shape pos\", tf.shape(pos))\n","        posCAMBIADO = tf.reshape(pos, (self.max_sequence_length, 1))\n","        print(\"pos CAMBIADO\", posCAMBIADO)\n","        print(\"shape pos CAMBIADO\", tf.shape(posCAMBIADO))\n","        pares = tf.sin(posCAMBIADO / denominador)\n","        print(\"pares\", pares)\n","        print(\"pares shape\", tf.shape(pares))\n","        impares = tf.cos(posCAMBIADO / denominador)\n","        pos_encoding = tf.concat([pares, impares], axis=-1)\n","        print(\"pos_encoding sumando pares e impares\", pos_encoding)\n","        print(\"pos_encoding sumando pares e impares\", tf.shape(pos_encoding))\n","        PE = inputs+ pos_encoding\n","        print(\"pos_encoding sumando los inputs\", PE)\n","        print(\"pos_encoding sumando los inputs\", tf.shape(PE))\n","        return PE\n"],"metadata":{"id":"lvasls-qdDvo","executionInfo":{"status":"ok","timestamp":1711622446334,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":304,"outputs":[]},{"cell_type":"markdown","source":[" EMBEDDING"],"metadata":{"id":"Q3snAkvC1DPd"}},{"cell_type":"code","source":["class SentenceEmbedding(tf.keras.layers.Layer):\n","    def __init__(self, max_sequence_length, d_model, vocab_size):\n","        super(SentenceEmbedding, self).__init__()\n","        self.vocab_size = vocab_size\n","        self.d_model = d_model\n","        self.embedding = tf.keras.layers.Embedding(self.vocab_size, d_model)\n","        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n","        self.dropout = tf.keras.layers.Dropout(rate=0.3)\n","\n","    def call(self, x):\n","        print(\"input\", x)\n","        x = self.embedding(x)\n","        print(\"after embedding\", x)\n","        x *=  tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n","        print(\"after normalizing\", x)\n","        x = self.position_encoder(x)\n","        print(\"after position encoder\", x)\n","        x = self.dropout(x)\n","        print(\"after dropout\", x)\n","        return x"],"metadata":{"id":"PC9zS0_6p1LD","executionInfo":{"status":"ok","timestamp":1711622447204,"user_tz":-60,"elapsed":8,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":305,"outputs":[]},{"cell_type":"markdown","source":["FEED FORDWARD"],"metadata":{"id":"K-pyDgyoCstc"}},{"cell_type":"code","source":["class FeedForward(tf.keras.layers.Layer):\n","    def __init__(self, d_model, hidden, drop_prob=0.1):\n","        super().__init__()\n","        self.seq = tf.keras.Sequential([\n","          tf.keras.layers.Dense(hidden, activation='relu'), #PRIMERO LO AMPLIO AL NUMERO DE NEURONAS QUE ME INDIQUE MI HIPERPARAMETRO HIDDEN\n","          tf.keras.layers.Dropout(drop_prob),#LE APLICO DROPOUT PARA EL OVERFITTING\n","          tf.keras.layers.Dense(d_model)#Y LO VUELVO A REDUCIR AL NUMERO INICIAL DE NEURONAS\n","        ])\n","        self.add = tf.keras.layers.Add()\n","        self.layer_norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","\n","\n","    def call(self, x):\n","        x = self.add([x, self.seq(x)]) #LE AÑADO EL VALOR RESIDUAL PARA NO TENER VANISING GRADIENTS\n","        x = self.layer_norm(x) #Y LO NORMALIZO\n","        return x\n"],"metadata":{"id":"lQ04lLTRCurb","executionInfo":{"status":"ok","timestamp":1711622447204,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":306,"outputs":[]},{"cell_type":"markdown","source":["ENCODER LAYER ( SE COMPONE DE UN MULTIHEAD ATTENTION CON MASK DE PADDING, UNA CAPA DE ADD Y NORMALIZATION Y UN FEEDFORDWARD (DENTRO DE ESTE ESTÁ YA IMPLEMENTADO EL ULTIMO ADD AND NORM)"],"metadata":{"id":"Qe4IN-g2EuOB"}},{"cell_type":"code","source":["class EncoderLayer(tf.keras.layers.Layer):\n","    def __init__(self, d_model, hidden, num_heads, drop_prob):\n","        super().__init__()\n","        self.attention = MultiHeadAttention(d_model, num_heads)\n","        self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","        self.dropout = tf.keras.layers.Dropout(drop_prob)\n","        self.ffn = FeedForward(d_model, hidden, drop_prob)\n","        self.add = tf.keras.layers.Add()\n","\n","    def call(self, x, mask = None, name = \"encoder_layer\"):\n","        residual = tf.identity(x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"residual shape:\", tf.shape(residual))\n","        print(\"residual:\", residual)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        x = self.attention({\"x\": x, \"mask\": mask})#padding mask\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"DESPUES DE ATTENTION shape:\", tf.shape(x))\n","        print(\"DESPUES DE ATTENTION:\", x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        x = self.dropout(x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de dropout shape:\", tf.shape(x))\n","        print(\"despues de dropout:\", x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        x = self.add([x, residual])\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de add shape:\", tf.shape(x))\n","        print(\"despues de add:\", x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        x = self.norm(x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de norm shape:\", tf.shape(x))\n","        print(\"despues de norm:\", x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        x = self.ffn(x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de fnn shape:\", tf.shape(x))\n","        print(\"despues de fnn:\", x)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        return x"],"metadata":{"id":"8DnNypu-EtpX","executionInfo":{"status":"ok","timestamp":1711622447204,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":307,"outputs":[]},{"cell_type":"markdown","source":["AHORA EL ECONDER ENTERO, TENGO QUE AÑADIR EL EMBEDDING, EL POSITIONAL ENCODER Y HACER LAS MULTICAPAS DE ENCODER"],"metadata":{"id":"EcdYm_y3YkH1"}},{"cell_type":"code","source":["import tensorflow as tf\n","\n","class Encoder(tf.keras.layers.Layer):\n","    def __init__(self, d_model, hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size):\n","        super(Encoder, self).__init__()\n","        self.sentence_embedding = SentenceEmbedding(max_sequence_length, d_model, vocab_size)\n","        self.layers = [EncoderLayer(d_model, hidden, num_heads, drop_prob) for _ in range(num_layers)]\n","        self.num_layers = num_layers\n","\n","    def call(self, x, mask):\n","        x = self.sentence_embedding(x)\n","        for i in range(self.num_layers):\n","            x = self.layers[i](x, mask)\n","            print(\"vueltas del encoder\", tf.shape(x))\n","        return x\n","\n"],"metadata":{"id":"Ftgc7CDgYjnd","executionInfo":{"status":"ok","timestamp":1711622447204,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":308,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"BeP_B9NZIsbL","executionInfo":{"status":"ok","timestamp":1711622447205,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":308,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"_vsfrNVlWdlX","executionInfo":{"status":"ok","timestamp":1711622447205,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":308,"outputs":[]},{"cell_type":"markdown","source":["ENCODER"],"metadata":{"id":"i2BV_LvzIMsC"}},{"cell_type":"code","source":["class EncDecAttention(tf.keras.layers.Layer):\n","  def __init__(self, d_model, num_heads):\n","      super(EncDecAttention, self).__init__()\n","      self.d_model = d_model  #es la embedding dimension\n","      self.num_heads = num_heads\n","      self.head_dim = d_model // num_heads #cada cabeza tiene esta dimension\n","      self.kv_layer = tf.keras.layers.Dense(2 * d_model) #hacemos la dimension de emmbedding por tres para hacer en el mismo tensor q, k y v\n","      self.q_layer = tf.keras.layers.Dense(d_model)\n","      self.linear_layer = tf.keras.layers.Dense(d_model)\n","\n","  def call(self, inputs):\n","        enc_outputs, dec_inputs, mask = (\n","            inputs[\"enc_outputs\"],#x\n","            inputs[\"dec_inputs\"],\n","            inputs[\"mask\"]\n","        )\n","        print(\"enc_outputs\", enc_outputs)\n","        print(\"dec_inputs\", dec_inputs)\n","        print(\"mask\", mask)\n","        #batch_size, sequence_length, d_model = tf.shape(enc_outputs) #entra como 4 (batch_size), 140 seq_lenght, 512 d_model\n","        batch_size, sequence_length, d_model = tf.compat.v1.Session().run(tf.compat.v1.shape(enc_outputs)).tolist()\n","        print(\"batch_size, sequence_length, d_model\", batch_size, sequence_length, d_model)\n","        print(\"tf.shape(x)\", tf.shape(enc_outputs))\n","        kv = self.kv_layer(enc_outputs) #lo pasamos de d_model a d_modelx3\n","        print(\"tf.shape(kv) por 2\", tf.shape(kv))\n","        q = self.q_layer(dec_inputs)\n","        print(\"tf.shape(q) por 1\", tf.shape(q))\n","        kv = tf.reshape(kv, (batch_size, sequence_length, self.num_heads, 2 * self.head_dim)) #lo dividimos en las cabezas\n","        print(\"tf.shape(kv) le cambiamos a 4 dim\", tf.shape(kv))\n","        q = tf.reshape(q, (batch_size, sequence_length, self.num_heads,  self.head_dim)) #lo dividimos en las cabezas\n","        print(\"tf.shape(q) le cambiamos a 4 dim\", tf.shape(q))\n","        kv = tf.transpose(kv, perm=(0, 2, 1, 3))#le cambiamod el orden para que esten las cabezas primero\n","        print(\"tf.shape(kv) cambiamos de orden la cabeza\", tf.shape(kv))\n","        q = tf.transpose(q, perm=(0, 2, 1, 3))#le cambiamod el orden para que esten las cabezas primero\n","        print(\"tf.shape(q) cambiamos de orden la cabeza\", tf.shape(q))\n","        k, v = tf.split(kv, num_or_size_splits=2, axis=-1)#lo dividimos en 2 por la ultima dimension\n","        print(\"kv\", tf.shape(k),tf.shape(v))\n","        values = scaled_dot_product(q, k, v, mask) #lo pasamos por la funcion de atencion que nos devuelve un tensor de 4, 8, 140, 64\n","        print(\"values\", tf.shape(values))#TENGO QUE METER EN LA LINEA DE ANTES MASKPADDING\n","        values = tf.reshape(tf.transpose(values, perm=(0, 2, 1, 3)), (batch_size, sequence_length, self.num_heads * self.head_dim)) #lo volvemos a poner primero seqlen y luego la dimension de las cabezas y las juntamos\n","        print(\"values cambiad0\", tf.shape(values))\n","        out = self.linear_layer(values)\n","        print(\"out\", tf.shape(out))\n","        print(\"out\", out)\n","        return out\n","\n"],"metadata":{"id":"gZF3M4K4IORW","executionInfo":{"status":"ok","timestamp":1711622447205,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":309,"outputs":[]},{"cell_type":"markdown","source":["PROBANDO LA CROSS ATTENTION"],"metadata":{"id":"pq8VBc-3snWJ"}},{"cell_type":"markdown","source":["DECODER LAYER"],"metadata":{"id":"yDz2VlCbs5wX"}},{"cell_type":"code","source":["class DecoderLayer(tf.keras.layers.Layer):\n","  def __init__(self, d_model, hidden, num_heads, drop_prob):\n","      super().__init__()\n","      self.attention1 = MultiHeadAttention(d_model, num_heads)\n","      self.norm = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","      self.dropout = tf.keras.layers.Dropout(drop_prob)\n","\n","      self.attention2 = EncDecAttention( d_model, num_heads)\n","      self.norm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n","      self.dropout2 = tf.keras.layers.Dropout(drop_prob)\n","      self.ffn = FeedForward(d_model, hidden, drop_prob)\n","      self.add = tf.keras.layers.Add()\n","  def call(self, enc_outputs, dec_inputs, lookAheadMask = None, encDecMask = None):\n","        residual = tf.identity(dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"residual shape:\", tf.shape(residual))\n","        print(\"residual:\", residual)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        dec_inputs = self.attention1({\"x\": dec_inputs, \"mask\": lookAheadMask})\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"DESPUES DE ATTENTION shape:\", tf.shape(dec_inputs))\n","        print(\"DESPUES DE ATTENTION:\", dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        dec_inputs = self.dropout(dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de dropout shape:\", tf.shape(dec_inputs))\n","        print(\"despues de dropout:\", dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        dec_inputs = self.add([dec_inputs, residual])\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de add shape:\", tf.shape(dec_inputs))\n","        print(\"despues de add:\", dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        dec_inputs = self.norm(dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de norm shape:\", tf.shape(dec_inputs))\n","        print(\"despues de norm:\", dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        residual = tf.identity(dec_inputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"residual shape:\", tf.shape(residual))\n","        print(\"residual:\", residual)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        encDecOutputs = self.attention2({\"enc_outputs\": enc_outputs,\"dec_inputs\":dec_inputs,  \"mask\": encDecMask})\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"DESPUES DE ATTENTION 222222shape:\", tf.shape(encDecOutputs))\n","        print(\"DESPUES DE ATTENTION:222\", encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        encDecOutputs = self.dropout2(encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de dropout 222222 shape:\", tf.shape(encDecOutputs))\n","        print(\"despues de dropout222222:\", encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        encDecOutputs = self.add([encDecOutputs, residual])\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de add 2222 shape:\", tf.shape(encDecOutputs))\n","        print(\"despues de 222add:\", encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        encDecOutputs = self.norm2(encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de norm 2222 shape:\", tf.shape(encDecOutputs))\n","        print(\"despues de 222norm:\", encDecOutputs)\n","        encDecOutputs = self.ffn(encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"despues de fnn shape:\", tf.shape(encDecOutputs))\n","        print(\"despues de fnn:\", encDecOutputs)\n","        print(\"-------------------------------------------------------------------------\")\n","        print(\"-------------------------------------------------------------------------\")\n","        return encDecOutputs\n"],"metadata":{"id":"GyMjGQv3s7T-","executionInfo":{"status":"ok","timestamp":1711622447205,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":310,"outputs":[]},{"cell_type":"markdown","source":["me queda el mask del cross attention\n"],"metadata":{"id":"GwNMAr_I-OvS"}},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","  def __init__(self,d_model, hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size):\n","      super().__init__()\n","      self.embedding = SentenceEmbedding(max_sequence_length, d_model, vocab_size)\n","      self.layers = [DecoderLayer(d_model, hidden, num_heads, drop_prob) for _ in range(num_layers)]\n","      self.num_layers = num_layers\n","\n","  def call(self,  enc_outputs, dec_inputs, lookAheadMask = None, encDecMask = None):\n","        dec_inputs = self.embedding(dec_inputs)\n","        for i in range(self.num_layers):\n","            dec_inputs = self.layers[i](enc_outputs, dec_inputs, lookAheadMask, encDecMask)\n","            print(\"vueltas del encoder\", tf.shape(dec_inputs))\n","        return dec_inputs"],"metadata":{"id":"AYMoPK5jgwtC","executionInfo":{"status":"ok","timestamp":1711622447643,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":311,"outputs":[]},{"cell_type":"markdown","source":["otra cosa que puedo hacer es cambiar la mask de orden en enc mask\n","\n","y otra peuba es usar la de google\n","\n","y otra prueba es cambiar los 24.4555 a 0"],"metadata":{"id":"Yszf0q_beJkz"}},{"cell_type":"markdown","source":["la clase transformer"],"metadata":{"id":"KxgzNmQ5EBOw"}},{"cell_type":"code","source":["class Transformer(tf.keras.Model):\n","  def __init__(self,d_model, hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size):\n","      super().__init__()\n","      self.encoder = Encoder(d_model, hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size)\n","      self.decoder = Decoder(d_model, hidden, num_heads, drop_prob, num_layers, max_sequence_length, vocab_size)\n","      self.linear = tf.keras.layers.Dense(vocab_size)\n","  def call(self,  inputs):\n","      try:\n","            enc_inputs, dec_inputs = (\n","                inputs[\"enc_inputs\"],\n","                inputs[\"dec_inputs\"]\n","            )\n","            print(tf.shape(enc_inputs))\n","            print(enc_inputs, \"ESTOS2\")\n","            encMask = crear_masks(enc_inputs)\n","            print(\"encMask\", encMask)\n","            lookmask = create_look_ahead_mask(dec_inputs)\n","            lookAheadMask = crear_masks(dec_inputs, lookmask)\n","            print(\"maskLookAhe\", lookAheadMask)\n","            maskCross = create_mask_cross(enc_inputs, dec_inputs)\n","            print(\"maskCross\", maskCross)\n","            x = self.encoder(enc_inputs, encMask)\n","            x = self.decoder(x, dec_inputs, lookAheadMask, maskCross)\n","            print(tf.shape(x))\n","            x = self.linear(x)\n","            print(tf.shape(x))\n","            print(\"FINAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL\", x)\n","\n","      except Exception as e:\n","            print(\"An exception occurred in Transformer call:\")\n","            print(str(e))\n","            # Puedes agregar más información de depuración aquí si es necesario\n","            raise e\n"],"metadata":{"id":"39LTR1JOCFDW","executionInfo":{"status":"ok","timestamp":1711622447643,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":312,"outputs":[]},{"cell_type":"markdown","source":["##ENTRENAMIENTO"],"metadata":{"id":"iKlOJmgl4EJK"}},{"cell_type":"code","execution_count":313,"metadata":{"id":"alnYEatYcHp7","pycharm":{"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1711622447990,"user_tz":-60,"elapsed":2,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6f5ca77a-113f-4996-9fdc-72425224efb9"},"outputs":[{"output_type":"stream","name":"stdout","text":["1031\n"]}],"source":["# For tf.data.Dataset\n","#BUFFER_SIZE = 20000\n","\n","\n","EPOCHS = 40\n","\n","BATCH_SIZE = 2\n","SEQUENCE_LENGTH = 120\n","D_MODEL = 512\n","HIDDEN = 1024\n","DROP_PROB = 0.1\n","NUM_HEADS = 8\n","NUM_LAYERS = 5\n","vocab_size = tokenizerTotal.get_vocab_size()+2\n","\n","print(vocab_size)"]},{"cell_type":"markdown","metadata":{"id":"0_GCb0LaV1tI","pycharm":{"name":"#%% md\n"}},"source":["### Loss function\n","\n","Since the target sequences are padded, it is important to apply a padding mask when calculating the loss."]},{"cell_type":"code","source":["def loss_function(y_true, y_pred):\n","    if y_true is None or y_pred is None:\n","        raise ValueError(\"y_true or y_pred is None\")\n","\n","    print(\"y_true shape:\", y_true.shape)\n","    print(\"y_true type:\", type(y_true))\n","    print(\"y_pred shape:\", y_pred.shape)\n","    print(\"y_pred type:\", type(y_pred))\n","\n","    loss = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=False, reduction=\"none\"\n","    )(y_true, y_pred)\n","\n","    mask = tf.cast(tf.not_equal(y_true, 0), tf.float32)\n","    loss = tf.multiply(loss, mask)\n","\n","    return tf.reduce_mean(loss)\n"],"metadata":{"id":"cbIm-w5bhSGV","executionInfo":{"status":"ok","timestamp":1711622448311,"user_tz":-60,"elapsed":322,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":314,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XvFM9ajSVybP","pycharm":{"name":"#%% md\n"}},"source":["### Custom learning rate\n","\n","Use the Adam optimizer with a custom learning rate scheduler according to the formula in the [paper](https://arxiv.org/abs/1706.03762).\n","\n","$$\\Large{lrate = d_{model}^{-0.5} * min(step{\\_}num^{-0.5}, step{\\_}num * warmup{\\_}steps^{-1.5})}$$"]},{"cell_type":"code","execution_count":315,"metadata":{"id":"WW3SeLDhAMJd","pycharm":{"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1711622448311,"user_tz":-60,"elapsed":4,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"outputs":[],"source":["class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n","    def __init__(self, d_model, warmup_steps=4000):\n","        super(CustomSchedule, self).__init__()\n","\n","        self.d_model = tf.constant(d_model)\n","        self.warmup_steps = warmup_steps\n","\n","    def get_config(self):\n","        return {\"d_model\": self.d_model, \"warmup_steps\": self.warmup_steps}\n","\n","    def __call__(self, step):\n","        print(\"custom \")\n","        arg1 = tf.math.rsqrt(step)\n","        arg2 = step * (self.warmup_steps**-1.5)\n","\n","        return tf.math.multiply(\n","            tf.math.rsqrt(self.d_model), tf.math.minimum(arg1, arg2)\n","        )"]},{"cell_type":"markdown","metadata":{"id":"cCqve3kwWCxd","pycharm":{"name":"#%% md\n"}},"source":["### Initialize and compile model\n","\n","Initialize and compile model with our predefined custom learning rate and Adam optimizer under the strategy scope."]},{"cell_type":"code","execution_count":316,"metadata":{"id":"1QqojIa5WEQq","pycharm":{"name":"#%%\n"},"executionInfo":{"status":"ok","timestamp":1711622448311,"user_tz":-60,"elapsed":3,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"outputs":[],"source":["# clear backend\n","tf.keras.backend.clear_session()\n","\n","learning_rate = 0.001\n","\n","optimizer = tf.keras.optimizers.Adam(\n","    learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9\n",")\n","\n","\n","def accuracy(y_true, y_pred):\n","    #ensure labels have shape (batch_size, SEQUENCE_LENGTH - 1)\n","    y_true = tf.reshape(y_true, shape=(-1, SEQUENCE_LENGTH - 1))\n","    print(\"accurCY\")\n","    return tf.keras.metrics.sparse_categorical_accuracy(y_true, y_pred)\n"]},{"cell_type":"code","source":["with strategy.scope():\n","    model = Transformer(D_MODEL, HIDDEN, NUM_HEADS, DROP_PROB, NUM_LAYERS, SEQUENCE_LENGTH, vocab_size)\n","\n","    model.compile(optimizer=optimizer, loss=loss_function)\n","\n"],"metadata":{"id":"iMooOacSOiHn","executionInfo":{"status":"ok","timestamp":1711622448675,"user_tz":-60,"elapsed":367,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":317,"outputs":[]},{"cell_type":"code","source":["numpy_iterator = tf.data.Dataset.get_single_element(dataset.batch(len(dataset)))\n","\n","# Convertir el iterador de TensorFlow a NumPy\n","dataset_values = list(tf.nest.map_structure(lambda x: x.numpy(), numpy_iterator))\n","\n","# Extraer cada parte en variables separadas\n","inputs_tensor = tf.convert_to_tensor(numpy_iterator[0]['inputs'])\n","dec_inputs_tensor = tf.convert_to_tensor(numpy_iterator[0]['dec_inputs'])\n","outputs_tensor = tf.convert_to_tensor(numpy_iterator[1]['outputs'])"],"metadata":{"id":"nQwUbi0Ncsfb","executionInfo":{"status":"ok","timestamp":1711622448675,"user_tz":-60,"elapsed":6,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}}},"execution_count":318,"outputs":[]},{"cell_type":"code","source":["inputs_tensor"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V20mKFddeWwt","executionInfo":{"status":"ok","timestamp":1711622448675,"user_tz":-60,"elapsed":5,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"e5bedbe2-5360-4b12-bb84-4206eeb58ea2"},"execution_count":319,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(9, 2, 120), dtype=int32, numpy=\n","array([[[  96,  168,  152, ...,   67,    4, 1030],\n","        [  96,  168,  152, ...,   67,    4, 1030]],\n","\n","       [[  96,  168,  152, ...,   67,    4, 1030],\n","        [  96,  168,  152, ...,   67,    4, 1030]],\n","\n","       [[ 607,   66,   37, ...,  687,    6, 1030],\n","        [ 607,   66,   37, ...,  687,    6, 1030]],\n","\n","       ...,\n","\n","       [[1029,  137,  391, ...,    0,    0,    0],\n","        [1029,  137,  391, ...,    0,    0,    0]],\n","\n","       [[1029,  137,  391, ...,    0,    0,    0],\n","        [1029,  218, 1005, ...,    0,    0,    0]],\n","\n","       [[1029,  285,  317, ...,    0,    0,    0],\n","        [1029,  285,  317, ...,    0,    0,    0]]], dtype=int32)>"]},"metadata":{},"execution_count":319}]},{"cell_type":"code","source":["train_dataset = tf.data.Dataset.from_tensor_slices((\n","    {\n","        \"enc_inputs\": inputs_tensor,\n","        \"dec_inputs\": dec_inputs_tensor\n","    },\n","    outputs_tensor  # aquí colocas tus etiquetas\n","))\n","\n","\n","print(train_dataset)\n","# Después, puedes llamar a model.fit directamente\n","model.fit(train_dataset, epochs=EPOCHS)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"tf98BLX9PTnY","executionInfo":{"status":"error","timestamp":1711622457882,"user_tz":-60,"elapsed":9212,"user":{"displayName":"Alejandro bazaco","userId":"10138017095433957529"}},"outputId":"697060ef-54de-4743-c7e3-c19418ed77d3"},"execution_count":320,"outputs":[{"output_type":"stream","name":"stdout","text":["<TensorSliceDataset element_spec=({'enc_inputs': TensorSpec(shape=(2, 120), dtype=tf.int32, name=None), 'dec_inputs': TensorSpec(shape=(2, 120), dtype=tf.int32, name=None)}, TensorSpec(shape=(2, 120), dtype=tf.int32, name=None))>\n","Epoch 1/40\n","Tensor(\"transformer/Shape:0\", shape=(2,), dtype=int32)\n","Tensor(\"IteratorGetNext:1\", shape=(2, 120), dtype=int32) ESTOS2\n","encMask Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","maskLookAhe Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","maskCross Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","input Tensor(\"IteratorGetNext:1\", shape=(2, 120), dtype=int32)\n","after embedding Tensor(\"transformer/encoder/sentence_embedding/embedding/embedding_lookup/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","after normalizing Tensor(\"transformer/encoder/sentence_embedding/mul:0\", shape=(2, 120, 512), dtype=float32)\n","i2 Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/range:0\", shape=(256,), dtype=float32)\n","i2 shape Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape:0\", shape=(1,), dtype=int32)\n","denominador Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Pow:0\", shape=(256,), dtype=float32)\n","denominador shape Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape_1:0\", shape=(1,), dtype=int32)\n","pos Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/range_1:0\", shape=(120,), dtype=float32)\n","shape pos Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape_2:0\", shape=(1,), dtype=int32)\n","pos CAMBIADO Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Reshape:0\", shape=(120, 1), dtype=float32)\n","shape pos CAMBIADO Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape_3:0\", shape=(2,), dtype=int32)\n","pares Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Sin:0\", shape=(120, 256), dtype=float32)\n","pares shape Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape_4:0\", shape=(2,), dtype=int32)\n","pos_encoding sumando pares e impares Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/concat:0\", shape=(120, 512), dtype=float32)\n","pos_encoding sumando pares e impares Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape_5:0\", shape=(2,), dtype=int32)\n","pos_encoding sumando los inputs Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/add:0\", shape=(2, 120, 512), dtype=float32)\n","pos_encoding sumando los inputs Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/Shape_6:0\", shape=(3,), dtype=int32)\n","after position encoder Tensor(\"transformer/encoder/sentence_embedding/positional_encoding/add:0\", shape=(2, 120, 512), dtype=float32)\n","after dropout Tensor(\"transformer/encoder/sentence_embedding/dropout/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/encoder/encoder_layer/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/encoder/encoder_layer/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/encoder/sentence_embedding/dropout/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/encoder/encoder_layer/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/encoder/encoder_layer/multi_head_attention/dense_1/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/encoder/encoder_layer/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/encoder/encoder_layer/dropout_1/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/encoder/encoder_layer/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/encoder/encoder_layer/add_1/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/encoder/encoder_layer/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/encoder/encoder_layer/layer_normalization/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/encoder/encoder_layer/Shape_5:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/encoder/encoder_layer/feed_forward/layer_normalization_1/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/encoder/Shape:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/encoder/encoder_layer_1/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/encoder/encoder_layer_1/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/encoder/encoder_layer/feed_forward/layer_normalization_1/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_5/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/encoder/encoder_layer_1/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/encoder/encoder_layer_1/multi_head_attention_1/dense_5/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/encoder/encoder_layer_1/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/encoder/encoder_layer_1/dropout_3/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/encoder/encoder_layer_1/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/encoder/encoder_layer_1/add_3/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/encoder/encoder_layer_1/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/encoder/encoder_layer_1/layer_normalization_2/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/encoder/encoder_layer_1/Shape_5:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/encoder/encoder_layer_1/feed_forward_1/layer_normalization_3/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/encoder/Shape_1:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/encoder/encoder_layer_2/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/encoder/encoder_layer_2/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/encoder/encoder_layer_1/feed_forward_1/layer_normalization_3/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_9/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/encoder/encoder_layer_2/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/encoder/encoder_layer_2/multi_head_attention_2/dense_9/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/encoder/encoder_layer_2/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/encoder/encoder_layer_2/dropout_5/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/encoder/encoder_layer_2/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/encoder/encoder_layer_2/add_5/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/encoder/encoder_layer_2/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/encoder/encoder_layer_2/layer_normalization_4/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/encoder/encoder_layer_2/Shape_5:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/encoder/encoder_layer_2/feed_forward_2/layer_normalization_5/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/encoder/Shape_2:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/encoder/encoder_layer_3/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/encoder/encoder_layer_3/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/encoder/encoder_layer_2/feed_forward_2/layer_normalization_5/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_13/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/encoder/encoder_layer_3/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/encoder/encoder_layer_3/multi_head_attention_3/dense_13/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/encoder/encoder_layer_3/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/encoder/encoder_layer_3/dropout_7/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/encoder/encoder_layer_3/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/encoder/encoder_layer_3/add_7/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/encoder/encoder_layer_3/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/encoder/encoder_layer_3/layer_normalization_6/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/encoder/encoder_layer_3/Shape_5:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/encoder/encoder_layer_3/feed_forward_3/layer_normalization_7/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/encoder/Shape_3:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/encoder/encoder_layer_4/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/encoder/encoder_layer_4/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/encoder/encoder_layer_3/feed_forward_3/layer_normalization_7/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_1:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/dense_17/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/encoder/encoder_layer_4/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/encoder/encoder_layer_4/multi_head_attention_4/dense_17/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/encoder/encoder_layer_4/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/encoder/encoder_layer_4/dropout_9/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/encoder/encoder_layer_4/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/encoder/encoder_layer_4/add_9/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/encoder/encoder_layer_4/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/encoder/encoder_layer_4/layer_normalization_8/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/encoder/encoder_layer_4/Shape_5:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/encoder/encoder_layer_4/feed_forward_4/layer_normalization_9/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/encoder/Shape_4:0\", shape=(3,), dtype=int32)\n","input Tensor(\"IteratorGetNext:0\", shape=(2, 120), dtype=int32)\n","after embedding Tensor(\"transformer/decoder/sentence_embedding_1/embedding_1/embedding_lookup/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","after normalizing Tensor(\"transformer/decoder/sentence_embedding_1/mul:0\", shape=(2, 120, 512), dtype=float32)\n","i2 Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/range:0\", shape=(256,), dtype=float32)\n","i2 shape Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape:0\", shape=(1,), dtype=int32)\n","denominador Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Pow:0\", shape=(256,), dtype=float32)\n","denominador shape Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape_1:0\", shape=(1,), dtype=int32)\n","pos Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/range_1:0\", shape=(120,), dtype=float32)\n","shape pos Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape_2:0\", shape=(1,), dtype=int32)\n","pos CAMBIADO Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Reshape:0\", shape=(120, 1), dtype=float32)\n","shape pos CAMBIADO Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape_3:0\", shape=(2,), dtype=int32)\n","pares Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Sin:0\", shape=(120, 256), dtype=float32)\n","pares shape Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape_4:0\", shape=(2,), dtype=int32)\n","pos_encoding sumando pares e impares Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/concat:0\", shape=(120, 512), dtype=float32)\n","pos_encoding sumando pares e impares Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape_5:0\", shape=(2,), dtype=int32)\n","pos_encoding sumando los inputs Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/add:0\", shape=(2, 120, 512), dtype=float32)\n","pos_encoding sumando los inputs Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/Shape_6:0\", shape=(3,), dtype=int32)\n","after position encoder Tensor(\"transformer/decoder/sentence_embedding_1/positional_encoding_1/add:0\", shape=(2, 120, 512), dtype=float32)\n","after dropout Tensor(\"transformer/decoder/sentence_embedding_1/dropout_11/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/decoder/sentence_embedding_1/dropout_11/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/dense_21/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/decoder/decoder_layer/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/decoder/decoder_layer/multi_head_attention_5/dense_21/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/decoder/decoder_layer/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/decoder/decoder_layer/dropout_12/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/decoder/decoder_layer/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/decoder/decoder_layer/add_11/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/decoder/decoder_layer/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer/Shape_5:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","enc_outputs Tensor(\"transformer/encoder/encoder_layer_4/feed_forward_4/layer_normalization_9/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","dec_inputs Tensor(\"transformer/decoder/decoder_layer/layer_normalization_10/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) por 2 Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(q) por 1 Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_3:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_4:0\", shape=(4,), dtype=int32)\n","tf.shape(q) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_5:0\", shape=(4,), dtype=int32)\n","tf.shape(kv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_6:0\", shape=(4,), dtype=int32)\n","tf.shape(q) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_7:0\", shape=(4,), dtype=int32)\n","kv Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_8:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_9:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/split:1\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_10:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_11:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/Shape_12:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/dense_24/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION 222222shape: Tensor(\"transformer/decoder/decoder_layer/Shape_6:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION:222 Tensor(\"transformer/decoder/decoder_layer/enc_dec_attention/dense_24/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout 222222 shape: Tensor(\"transformer/decoder/decoder_layer/Shape_7:0\", shape=(3,), dtype=int32)\n","despues de dropout222222: Tensor(\"transformer/decoder/decoder_layer/dropout_13/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add 2222 shape: Tensor(\"transformer/decoder/decoder_layer/Shape_8:0\", shape=(3,), dtype=int32)\n","despues de 222add: Tensor(\"transformer/decoder/decoder_layer/add_11/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm 2222 shape: Tensor(\"transformer/decoder/decoder_layer/Shape_9:0\", shape=(3,), dtype=int32)\n","despues de 222norm: Tensor(\"transformer/decoder/decoder_layer/layer_normalization_11/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/decoder/decoder_layer/Shape_10:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/decoder/decoder_layer/feed_forward_5/layer_normalization_12/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/decoder/Shape:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_1/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/decoder/decoder_layer/feed_forward_5/layer_normalization_12/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_28/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/decoder/decoder_layer_1/multi_head_attention_6/dense_28/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/decoder/decoder_layer_1/dropout_15/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/decoder/decoder_layer_1/add_13/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_5:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_1/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","enc_outputs Tensor(\"transformer/encoder/encoder_layer_4/feed_forward_4/layer_normalization_9/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","dec_inputs Tensor(\"transformer/decoder/decoder_layer_1/layer_normalization_13/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) por 2 Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(q) por 1 Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_3:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_4:0\", shape=(4,), dtype=int32)\n","tf.shape(q) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_5:0\", shape=(4,), dtype=int32)\n","tf.shape(kv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_6:0\", shape=(4,), dtype=int32)\n","tf.shape(q) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_7:0\", shape=(4,), dtype=int32)\n","kv Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_8:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_9:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/split:1\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_10:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_11:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/Shape_12:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/dense_31/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION 222222shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_6:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION:222 Tensor(\"transformer/decoder/decoder_layer_1/enc_dec_attention_1/dense_31/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout 222222 shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_7:0\", shape=(3,), dtype=int32)\n","despues de dropout222222: Tensor(\"transformer/decoder/decoder_layer_1/dropout_16/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add 2222 shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_8:0\", shape=(3,), dtype=int32)\n","despues de 222add: Tensor(\"transformer/decoder/decoder_layer_1/add_13/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm 2222 shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_9:0\", shape=(3,), dtype=int32)\n","despues de 222norm: Tensor(\"transformer/decoder/decoder_layer_1/layer_normalization_14/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/decoder/decoder_layer_1/Shape_10:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/decoder/decoder_layer_1/feed_forward_6/layer_normalization_15/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/decoder/Shape_1:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_2/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/decoder/decoder_layer_1/feed_forward_6/layer_normalization_15/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/dense_35/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/decoder/decoder_layer_2/multi_head_attention_7/dense_35/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/decoder/decoder_layer_2/dropout_18/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/decoder/decoder_layer_2/add_15/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_5:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_2/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","enc_outputs Tensor(\"transformer/encoder/encoder_layer_4/feed_forward_4/layer_normalization_9/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","dec_inputs Tensor(\"transformer/decoder/decoder_layer_2/layer_normalization_16/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) por 2 Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(q) por 1 Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_3:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_4:0\", shape=(4,), dtype=int32)\n","tf.shape(q) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_5:0\", shape=(4,), dtype=int32)\n","tf.shape(kv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_6:0\", shape=(4,), dtype=int32)\n","tf.shape(q) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_7:0\", shape=(4,), dtype=int32)\n","kv Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_8:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_9:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/split:1\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_10:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_11:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/Shape_12:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/dense_38/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION 222222shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_6:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION:222 Tensor(\"transformer/decoder/decoder_layer_2/enc_dec_attention_2/dense_38/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout 222222 shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_7:0\", shape=(3,), dtype=int32)\n","despues de dropout222222: Tensor(\"transformer/decoder/decoder_layer_2/dropout_19/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add 2222 shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_8:0\", shape=(3,), dtype=int32)\n","despues de 222add: Tensor(\"transformer/decoder/decoder_layer_2/add_15/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm 2222 shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_9:0\", shape=(3,), dtype=int32)\n","despues de 222norm: Tensor(\"transformer/decoder/decoder_layer_2/layer_normalization_17/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/decoder/decoder_layer_2/Shape_10:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/decoder/decoder_layer_2/feed_forward_7/layer_normalization_18/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/decoder/Shape_2:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_3/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/decoder/decoder_layer_2/feed_forward_7/layer_normalization_18/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/dense_42/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/decoder/decoder_layer_3/multi_head_attention_8/dense_42/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/decoder/decoder_layer_3/dropout_21/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/decoder/decoder_layer_3/add_17/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_5:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_3/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","enc_outputs Tensor(\"transformer/encoder/encoder_layer_4/feed_forward_4/layer_normalization_9/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","dec_inputs Tensor(\"transformer/decoder/decoder_layer_3/layer_normalization_19/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) por 2 Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(q) por 1 Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_3:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_4:0\", shape=(4,), dtype=int32)\n","tf.shape(q) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_5:0\", shape=(4,), dtype=int32)\n","tf.shape(kv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_6:0\", shape=(4,), dtype=int32)\n","tf.shape(q) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_7:0\", shape=(4,), dtype=int32)\n","kv Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_8:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_9:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/split:1\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_10:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_11:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/Shape_12:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/dense_45/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION 222222shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_6:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION:222 Tensor(\"transformer/decoder/decoder_layer_3/enc_dec_attention_3/dense_45/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout 222222 shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_7:0\", shape=(3,), dtype=int32)\n","despues de dropout222222: Tensor(\"transformer/decoder/decoder_layer_3/dropout_22/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add 2222 shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_8:0\", shape=(3,), dtype=int32)\n","despues de 222add: Tensor(\"transformer/decoder/decoder_layer_3/add_17/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm 2222 shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_9:0\", shape=(3,), dtype=int32)\n","despues de 222norm: Tensor(\"transformer/decoder/decoder_layer_3/layer_normalization_20/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/decoder/decoder_layer_3/Shape_10:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/decoder/decoder_layer_3/feed_forward_8/layer_normalization_21/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/decoder/Shape_3:0\", shape=(3,), dtype=int32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_4/Identity:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","x Tensor(\"transformer/decoder/decoder_layer_3/feed_forward_8/layer_normalization_21/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) por 3 Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(qkv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_3:0\", shape=(4,), dtype=int32)\n","tf.shape(qkv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_4:0\", shape=(4,), dtype=int32)\n","qkv Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_5:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_6:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_7:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_3:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/split:2\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_8:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_9:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/Shape_10:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/dense_49/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_1:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION: Tensor(\"transformer/decoder/decoder_layer_4/multi_head_attention_9/dense_49/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_2:0\", shape=(3,), dtype=int32)\n","despues de dropout: Tensor(\"transformer/decoder/decoder_layer_4/dropout_24/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_3:0\", shape=(3,), dtype=int32)\n","despues de add: Tensor(\"transformer/decoder/decoder_layer_4/add_19/add:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_4:0\", shape=(3,), dtype=int32)\n","despues de norm: Tensor(\"transformer/decoder/decoder_layer_4/layer_normalization_22/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","residual shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_5:0\", shape=(3,), dtype=int32)\n","residual: Tensor(\"transformer/decoder/decoder_layer_4/Identity_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","enc_outputs Tensor(\"transformer/encoder/encoder_layer_4/feed_forward_4/layer_normalization_9/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","dec_inputs Tensor(\"transformer/decoder/decoder_layer_4/layer_normalization_22/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","mask Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","batch_size, sequence_length, d_model 2 120 512\n","tf.shape(x) Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_1:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) por 2 Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_2:0\", shape=(3,), dtype=int32)\n","tf.shape(q) por 1 Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_3:0\", shape=(3,), dtype=int32)\n","tf.shape(kv) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_4:0\", shape=(4,), dtype=int32)\n","tf.shape(q) le cambiamos a 4 dim Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_5:0\", shape=(4,), dtype=int32)\n","tf.shape(kv) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_6:0\", shape=(4,), dtype=int32)\n","tf.shape(q) cambiamos de orden la cabeza Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_7:0\", shape=(4,), dtype=int32)\n","kv Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_8:0\", shape=(4,), dtype=int32) Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_9:0\", shape=(4,), dtype=int32)\n","maaaaask look ahead Tensor(\"transformer/Maximum_5:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS ANTES Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/truediv:0\", shape=(2, 8, 120, 120), dtype=float32)\n","MASK * NEG Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/mul:0\", shape=(2, 1, 120, 120), dtype=float32)\n","PARENTESIS DESPUES Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/add:0\", shape=(2, 8, 120, 120), dtype=float32)\n","---------------------------------------------------------\n","ATEENTION Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Softmax:0\", shape=(2, 8, 120, 120), dtype=float32)\n","V Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/split:1\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/MatMul_1:0\", shape=(2, 8, 120, 64), dtype=float32)\n","values Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_10:0\", shape=(4,), dtype=int32)\n","values cambiad0 Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_11:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/Shape_12:0\", shape=(3,), dtype=int32)\n","out Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/dense_52/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","DESPUES DE ATTENTION 222222shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_6:0\", shape=(3,), dtype=int32)\n","DESPUES DE ATTENTION:222 Tensor(\"transformer/decoder/decoder_layer_4/enc_dec_attention_4/dense_52/BiasAdd:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de dropout 222222 shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_7:0\", shape=(3,), dtype=int32)\n","despues de dropout222222: Tensor(\"transformer/decoder/decoder_layer_4/dropout_25/dropout/Mul_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de add 2222 shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_8:0\", shape=(3,), dtype=int32)\n","despues de 222add: Tensor(\"transformer/decoder/decoder_layer_4/add_19/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de norm 2222 shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_9:0\", shape=(3,), dtype=int32)\n","despues de 222norm: Tensor(\"transformer/decoder/decoder_layer_4/layer_normalization_23/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","despues de fnn shape: Tensor(\"transformer/decoder/decoder_layer_4/Shape_10:0\", shape=(3,), dtype=int32)\n","despues de fnn: Tensor(\"transformer/decoder/decoder_layer_4/feed_forward_9/layer_normalization_24/batchnorm/add_1:0\", shape=(2, 120, 512), dtype=float32)\n","-------------------------------------------------------------------------\n","-------------------------------------------------------------------------\n","vueltas del encoder Tensor(\"transformer/decoder/Shape_4:0\", shape=(3,), dtype=int32)\n","Tensor(\"transformer/Shape_4:0\", shape=(3,), dtype=int32)\n","Tensor(\"transformer/Shape_5:0\", shape=(3,), dtype=int32)\n","FINAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAL Tensor(\"transformer/dense_55/BiasAdd:0\", shape=(2, 120, 1031), dtype=float32)\n"]},{"output_type":"error","ename":"AttributeError","evalue":"in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 199, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 727, in match_dtype_and_rank\n        (y_t.dtype.is_integer and y_p.dtype.is_integer)):\n\n    AttributeError: 'NoneType' object has no attribute 'dtype'\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-320-6944515195ac>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Después, puedes llamar a model.fit directamente\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1051, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1040, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1030, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 890, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 948, in compute_loss\n        return self.compiled_loss(\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 199, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/compile_utils.py\", line 727, in match_dtype_and_rank\n        (y_t.dtype.is_integer and y_p.dtype.is_integer)):\n\n    AttributeError: 'NoneType' object has no attribute 'dtype'\n"]}]}]}