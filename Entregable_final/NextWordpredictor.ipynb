{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mxDFgGjieggr"
      },
      "outputs": [],
      "source": [
        "#imports\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load the dataset\n",
        "\n",
        "def cargandoDataset():\n",
        "  return"
      ],
      "metadata": {
        "id": "ynG0UigGfUVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#analizando el dataset\n",
        "texto = cargandoDataset\n",
        "print(f\"El texto tiene{len(texto)} caracteres\\n\")\n",
        "print(f\"los primeros 200 son asi:\\n\")\n",
        "print(texto[:200])\n",
        "\n",
        "texto_por_frases = texto.lower().split(\"\\n\")\n",
        "print(f\"el texto tiene{len(texto_por_frases)} frases\")\n"
      ],
      "metadata": {
        "id": "MZKDeeQefkHD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#limpiamos el dataset"
      ],
      "metadata": {
        "id": "9KvNdySah3C3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#iniciamos el tokenizador\n",
        "tokenizer = Tokenizer()#no ponemos num_words porque queremos todas las palabras y no ponemos oov\n",
        "tokenizer.fit_on_texts(texto_por_frases)\n",
        "word_index = tokenizer.word_index\n",
        "num_palabras = len(word_index)+1#el valor 0 es para el padding\n",
        "\n",
        "print(f\"el word index es asi{word_index}\")\n",
        "print(f\"el numero de palabras en el texto es{num_palabras}\")"
      ],
      "metadata": {
        "id": "z6bbc3u8hP78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#funcion para hacer los n-grams\n",
        "\n",
        "def n_grams(texto, tokenizer):\n",
        "  n-gramas=[]\n",
        "  max_ = 0\n",
        "  for frase in texto:\n",
        "    secuencia = tokenizer.texts_to_sequences([frase])[0]\n",
        "    max_ = max(max_, len(secuencia))\n",
        "    for i in range(2, len(secuencia) + 1):\n",
        "        ngrama = secuencia[:i]\n",
        "        n-gramas.append(ngrama)\n",
        "\n",
        "  return n-gramas, max_"
      ],
      "metadata": {
        "id": "JWeL8RQ1jgBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_gramas, max_ = ngrams(texto, tokenizer)\n",
        "print(f\"el tamaño maximo de los ngramas es {max_}\")\n",
        "print(f\"el tamaño de los ngramas es {len(n_gramas)}\")\n",
        "print(f\"un ejemplo es {n_gramas[0:5]}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "GO3MwYBpm3rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#borrar\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "\n",
        "print(f\"n_grams of input_sequences have length: {len(input_sequences)}\")\n",
        "print(f\"maximum length of sequences is: {max_sequence_len}\")"
      ],
      "metadata": {
        "id": "p1LrIu3RoHmS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#añadimos el padding\n",
        "n_gramas_padded = pad_sequence(n_gramas, maxlen= max_, padding=\"pre\")\n",
        "\n",
        "print(f\"el tamaño de los ngramas paddeados es {len(n_gramas_padded)}\")\n",
        "print(f\"un ejemplo es {n_gramas_padded[0:5]}\")"
      ],
      "metadata": {
        "id": "tgaxTHeeoaRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dividimos en frase y label\n",
        "xs = n_gramas_padded[:,:-1]#todos los tokens salvo el ultimo\n",
        "ys = n_gramas_padded[:,-1]#el ultimo\n",
        "ys_hot = to_categorical(ys, num_palabras) #one hot encoding"
      ],
      "metadata": {
        "id": "MR62NE_-o74M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def crear_Modelo(NUM_PALABRAS, EMBEDDING_DIM, LONGITUD_MAX):\n",
        "  model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(NUM_PALABRAS, EMBEDDING_DIM, input_length = LONGITUD_MAX),\n",
        "        tf.keras.layers.Bidirectional(tensorflow.keras.layers.LSTM(250)),\n",
        "        tf.keras.layers.DenseDense(NUM_PALABRAS*2, activation='relu'),\n",
        "        tf.keras.layers.Dense(NUM_PALABRAS, activation='softmax')\n",
        "\n",
        "    ])\n",
        "\n",
        "  adam =  tf.keras.optimizers.Adam(lr=0.0008)\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=adam,\n",
        "                  metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "_TNXD7gPpwp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo = crear_Modelo(num_palabras, 100, max_)\n",
        "datosGraficas = modelo.fit(xs, ys_hot, epochs = 50, verbose = 2)"
      ],
      "metadata": {
        "id": "yfawkwC5sp9b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    accuracy = datosGraficas.history['accuracy']\n",
        "    loss = datosGraficas.history['loss']\n",
        "\n",
        "\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
        "\n",
        "    # Gráfica de precision\n",
        "    ax1.plot(accuracy, label='accuracy')\n",
        "    ax1.set_title('Precision')\n",
        "    ax1.set_xlabel('Epoch')\n",
        "    ax1.set_ylabel('Precision')\n",
        "    ax1.legend()\n",
        "\n",
        "    # Gráfica de loss\n",
        "    ax2.plot(loss, label='Loss')\n",
        "    ax2.set_title('Perdida')\n",
        "    ax2.set_xlabel('Epoch')\n",
        "    ax2.set_ylabel('Perdida')\n",
        "    ax2.legend()\n",
        "\n",
        "    # Ajustar el espaciado entre subgráficos\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Mostrar las gráficas\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SAQE8tqmt6OD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}